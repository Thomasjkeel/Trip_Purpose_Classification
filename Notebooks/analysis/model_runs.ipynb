{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model runs for Trip Purpose Estimation using data from the 2017 MTL Trajet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import rfpimp\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "# oversampling\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should contain the nearby POI information from the Google Place API. \n",
    "\n",
    "`Preprocessing is needed`\n",
    "\n",
    "Consider using the POI types from the paper by Emagun et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.read_csv('../../Data/model_inputs/gdf_2017_X.csv')\n",
    "y_all = pd.read_csv('../../Data/model_inputs/gdf_2017_y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding of **purpose** and **mode** is as follows. Note that the trips of home and work have been removed.\n",
    "\n",
    "- purpose: {'leisure': 0, 'food_drink': 1, 'shops': 2, 'pick_up_drop_off': 3, 'education': 4, 'health': 5}\n",
    "- mode: {'walking': 0, 'public_transport': 1, 'car': 2, 'cycling': 3, 'taxi': 4, 'car_sharing': 5,'mixed':6, 'other':7, 'not_available':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9143\n",
       "2    8357\n",
       "1    3107\n",
       "4    2769\n",
       "3    1571\n",
       "5    1044\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    9906\n",
       "0    5913\n",
       "3    3514\n",
       "1    3380\n",
       "6    2635\n",
       "5     407\n",
       "4     111\n",
       "8      65\n",
       "7      60\n",
       "Name: mode, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_trip', 'mode', 'distance_m', 'duration', 'weekday', 'morning',\n",
       "       'midday', 'afternoon', 'evening', 'midnight', 'lat', 'long'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of X variables is shown below.\n",
    "\n",
    "| Variable | Meaning | Unit |\n",
    "|:-------- | :-------- | :---- |\n",
    "| id_trip | Unique ID | NA |\n",
    "| mode | Trip mode | {'walking': 0, 'public_transport': 1, 'car': 2, 'cycling': 3, 'taxi': 4, 'car_sharing': 5,'mixed':6, 'other':7, 'not_available':8}|\n",
    "| duration | Trip duration | Second |\n",
    "| distance_m | Euclidean trip distance calculated from nodes along a Shapely LineString object | Metre |\n",
    "| weekday | Whether this trip occurs in a weekday (Monday to Friday) | {1:True, 0:False} |\n",
    "| precip | Total precipitation within a given hour on a given date | mm |\n",
    "| temp | Average Temperature within a given hour on a given date | Celcius |\n",
    "| morning | Whether this trip occurs in the morning time 0600-1059 | {1:True, 0:False} |\n",
    "| afternoon | Whether this trip occurs in the afternoon time 1100-1359 | {1:True, 0:False} |\n",
    "| evening | Whether this trip occurs in the evening time 1700-2159 | {1:True, 0:False} |\n",
    "| midnight | Whether this trip occurs in the midnight time 2200-0559 | {1:True, 0:False} |\n",
    "| long | The x coordinate of the ending point in the TBC reference system | Metre |\n",
    "| lat | The y coordinate of the ending point in the TBC reference system | Metre |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace False and True with 0 and 1, respectively\n",
    "X_all = X_all.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add descriptive analysis of nearby POIs, and compare this with the description of LTPD (in Section 5.1) [Thomas] X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['purpose'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of each trip purpose:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    9143\n",
       "2    8357\n",
       "1    3107\n",
       "4    2769\n",
       "3    1571\n",
       "5    1044\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The size of each trip purpose:')\n",
    "y_all['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable settings and algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are four settings of variables\n",
    " - Basic (without nearby trip purposes or Google nearby Places)\n",
    " - Basic and nearby trips\n",
    " - Basic and Google POIs\n",
    " - Baisc and nearby trips and Google POIs \n",
    " \n",
    " \n",
    " There are two algorithms:\n",
    " - Random Forest\n",
    " - Nested Logit\n",
    " \n",
    " \n",
    " Based on exhaustive combinations of settings and algorithms, eight models will be trained.\n",
    " \n",
    " In this notebook, we will compare four random forest models. Each model will be tuned using GridSearchCV.\n",
    " \n",
    " The basic variables include the following:\n",
    " - 'mode'\n",
    " - 'duration'\n",
    " - 'distance_m'\n",
    " - 'weekday'\n",
    " - 'precip'\n",
    " - 'temp'\n",
    " - 'morning' \n",
    " - 'midday' \n",
    " - 'afternoon'\n",
    " - 'evening'\n",
    " - 'midnight'\n",
    " \n",
    " \n",
    " There is no need to normalise continuous variables before using RF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function for re-projecting that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_crs_of_X(X, crs_from=\"EPSG:4236\",crs_to=\"EPSG:3347\"):\n",
    "    \"\"\"\n",
    "        Function for translating the data into Canada Lambert projection \n",
    "        EPSG: 3347, so that the base unit is 1 m\n",
    "    \"\"\"\n",
    "    new_X = X.copy()\n",
    "    new_X['geometry'] = new_X.apply(lambda row: shapely.geometry.Point(row['long'],row['lat']),axis=1)\n",
    "    new_X = gpd.GeoDataFrame(new_X,crs=crs_from)\n",
    "    new_X = new_X.to_crs(crs_to)\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function that runs a standard random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(X_train, X_test, y_train, y_test, n_estimators=100, max_depth=None):\n",
    "    \"\"\"\n",
    "        Run a random forest classification model\n",
    "    \"\"\"\n",
    "    clf = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    preds = clf.predict(X_test)\n",
    "    #print(\"Random Forest Classifcation accuracy:\", score)\n",
    "    return clf, score, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to compute the proportions of nearby trip purposes in the training data (TK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nearby_purposes(y_train, X_train, X_test, buffer_size_m=200):\n",
    "    \"\"\"\n",
    "        Augment the training and testing data with the proportions of nearby trip purposes in the training data.\n",
    "        :param y_train: (dataframe) the trip purpose of the training data, which is used to compute proportions of nearby trip purposes. Should contain a column of 'purpose'\n",
    "        :param X_train: (dataframe) the predictor variables of the training data. Should contain three columns of 'id', endx' and 'endy'.\n",
    "        :param X_test: (dataframe) the predictor variables of the testing data. Should contain two columns of 'id', 'endx' and 'endy'.\n",
    "        :param buffer_size_m: (int) the size of the buffer in metres around each trip end.\n",
    "        :return: (list) [X_train_aug, X_test_aug]. X_train_aug and X_test_aug are the X_train and X_test augmented with extra columns, respectively. The new columns are ['p_nearby_0', 'p_nearby_1', 'p_nearby_2', 'p_nearby_3', 'p_nearby_4', 'p_nearby_5']\n",
    "        Note: when selecting the trips close to a trip in the training data, remember to exclude this trip itself using the 'id' column.\n",
    "        Note: EPSG:3347 == Canada Lambert Projection\n",
    "    \"\"\"\n",
    "    ## merge train and test X back together\n",
    "    all_X = pd.concat([X_train, X_test],axis=0)\n",
    "    \n",
    "    ## initialise a geo-dataframe of all the X values and create a buffer of 200 m around each trip (for each row)\n",
    "    geo_X = change_crs_of_X(all_X)\n",
    "    \n",
    "    # calculate 200 m buffers around each trip end point\n",
    "    geo_X['buffers'] = geo_X['geometry'].apply(lambda row: row.buffer(buffer_size_m))\n",
    "    \n",
    "    # get a geo-dataframe with only the Trip ID,trip end buffer and trip purpose\n",
    "    only_buffers = geo_X[['id_trip','buffers']]\n",
    "    only_buffers = gpd.GeoDataFrame(only_buffers.rename(columns={'buffers':'geometry'}), crs=\"EPSG:3347\")\n",
    "    \n",
    "    \n",
    "    ## intialise a geo-dataframe of only the training data\n",
    "    # Note: only the purposes of trips of the training dataset are known so this is why we need to create a seperate geoDataFrame of only the training data\n",
    "    all_train = pd.concat([X_train,y_train],axis=1)\n",
    "    all_train.reset_index(drop=True,inplace=True)\n",
    "    geo_train = change_crs_of_X(all_train)\n",
    "\n",
    "    ## perform the spatial join between a buffer of each trip and trip end points from exclusively the training data.\n",
    "    # Note: here we are extracting the purpose of trips where the trip end points from the training geo-dataframe (type==Point) intersect with a buffer of all the trip end points (type==Polygon) \n",
    "    joined_data = gpd.sjoin(only_buffers, geo_train, op='intersects', how='left')\n",
    "\n",
    "    ## drop duplicates (as each trip will fall within a buffer of itself)\n",
    "    to_drop = joined_data[['id_trip_left','id_trip_right']].apply(lambda row: True \\\n",
    "                                                                if row['id_trip_left'] == row['id_trip_right']\\\n",
    "                                                                else False, axis=1)\n",
    "    joined_data = joined_data[~to_drop]\n",
    "    \n",
    "    ## Compute the proportion of nearby purposes types for each trip/row\n",
    "    grouped_data = joined_data.groupby(['id_trip_left', 'purpose']).agg({'mode':'count'})\n",
    "    grouped_data = grouped_data.unstack().apply(lambda row: row/row.sum(),axis=1)['mode'].reset_index()\n",
    "    grouped_data = grouped_data.fillna(0.0)\n",
    "    \n",
    "    ## rename columns\n",
    "    new_columns = ['id_trip','p_nearby_0','p_nearby_1','p_nearby_2','p_nearby_3','p_nearby_4',\\\n",
    "                       'p_nearby_5']\n",
    "    grouped_data.columns = new_columns\n",
    "    \n",
    "    ## Merge p_nearby columns back to X_train and X_test\n",
    "    all_X = all_X.merge(grouped_data, on='id_trip', how='left')\n",
    "    all_X = all_X.fillna(0.0)\n",
    "    X_train_aug = X_train.merge(all_X[new_columns], on='id_trip')\n",
    "    X_test_aug = X_test.merge(all_X[new_columns], on='id_trip')\n",
    "    return X_train_aug, X_test_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_variables = ['mode', 'duration', 'distance_m', 'weekday',\n",
    "    'morning', 'midday', 'afternoon', 'evening', 'midnight']\n",
    "\n",
    "# needed for nearby purpose computation \n",
    "temporary_variables = ['id_trip','long','lat']\n",
    "\n",
    "# extract all variables\n",
    "X_all_basic_variables = X_all[basic_variables + temporary_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25991, 12)\n",
      "(25991, 1)\n",
      "(25991,)\n"
     ]
    }
   ],
   "source": [
    "print(X_all_basic_variables.shape)\n",
    "print(y_all.shape)\n",
    "print(np.ravel(y_all).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training testing data\n",
    "rd_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    X_all_basic_variables, y_all, stratify=y_all, random_state=rd_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute nearby purposes\n",
    "X_train, X_test = compute_nearby_purposes(y_train, X_train, X_test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve Trip IDs of training and testing data\n",
    "X_train_IDs = X_train['id_trip']\n",
    "X_test_IDs = X_test['id_trip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove columns which are not needed\n",
    "X_train = X_train.drop(columns=temporary_variables, axis=1)\n",
    "X_test = X_test.drop(columns=temporary_variables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten y train data\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the random forest algorithm on this dataset\n",
    "rf_clf, rf_accuracy_rest, rf_pred_test = run_rf(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  1.0\n",
      "Accuracy on testing data:  0.5357032933210218\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(\"Accuracy on training data: \", rf_clf.score(X_train, y_train))\n",
    "print(\"Accuracy on testing data: \", rf_accuracy_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediciton accuracy on the training and testing data is 1.0 and 0.511, respectively, indicating that the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60      2286\n",
      "           1       0.33      0.13      0.19       777\n",
      "           2       0.52      0.59      0.56      2089\n",
      "           3       0.39      0.19      0.25       393\n",
      "           4       0.72      0.71      0.72       692\n",
      "           5       0.35      0.14      0.20       261\n",
      "\n",
      "    accuracy                           0.54      6498\n",
      "   macro avg       0.48      0.41      0.42      6498\n",
      "weighted avg       0.51      0.54      0.51      6498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that the F1 is the highest for the trips of type 0 and 2, and the lowest for type 3 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples is set as 5000 by default. \n",
    "# Setting n_samples as -1 means entire validation set\n",
    "# the score metric used is accuracy, aka number of records that are correctly predicted\n",
    "imp = rfpimp.importances(rf_clf, X_test, y_test, n_samples=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Importance\n",
      "Feature               \n",
      "p_nearby_4    0.042629\n",
      "p_nearby_2    0.030471\n",
      "midnight      0.028163\n",
      "weekday       0.021237\n",
      "p_nearby_0    0.013697\n",
      "midday        0.010773\n",
      "mode          0.008310\n",
      "evening       0.007387\n",
      "distance_m    0.006925\n",
      "duration      0.006464\n",
      "morning       0.001385\n",
      "p_nearby_3    0.001231\n",
      "p_nearby_5    0.001231\n",
      "afternoon    -0.002924\n",
      "p_nearby_1   -0.003540\n"
     ]
    }
   ],
   "source": [
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x239.04 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz = rfpimp.plot_importances(imp)\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the most important variables are:\n",
    "- purpose_nearby_2 # shops\n",
    "- purpose_nearby_4 # education\n",
    "- mode\n",
    "- temp\n",
    "- purpose_nearby_0 # leisure\n",
    "- weekday\n",
    "- purpose_nearby_1 # food/drink\n",
    "- distance_m\n",
    "- purpose_nearby_3 # pick-up/drop-off\n",
    "- purpose_nearby_5 # health\n",
    "- midnight\n",
    "- duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter of **n_estimators** will be tuned using *GridSearchCV*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 200}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.540 (+/-0.011) for {'n_estimators': 10}\n",
      "0.564 (+/-0.017) for {'n_estimators': 50}\n",
      "0.568 (+/-0.019) for {'n_estimators': 100}\n",
      "0.570 (+/-0.015) for {'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full evaluation set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.60      2286\n",
      "           1       0.35      0.13      0.19       777\n",
      "           2       0.53      0.60      0.56      2089\n",
      "           3       0.36      0.17      0.23       393\n",
      "           4       0.73      0.71      0.72       692\n",
      "           5       0.36      0.15      0.21       261\n",
      "\n",
      "    accuracy                           0.54      6498\n",
      "   macro avg       0.48      0.41      0.42      6498\n",
      "weighted avg       0.52      0.54      0.51      6498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on different n_estimators\n",
    "list_n_estimators = [10, 50, 100, 200]\n",
    "\n",
    "# by default n_estimator in random forest is 100\n",
    "parameters = {'n_estimators': list_n_estimators}\n",
    "\n",
    "# use the default 5-fold cross validation. \n",
    "# About CV: For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. \n",
    "# In all other cases, KFold is used.\n",
    "gscv_rfc = sklearn.model_selection.GridSearchCV(sklearn.ensemble.RandomForestClassifier(), parameters)\n",
    "gscv_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(gscv_rfc.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = gscv_rfc.cv_results_['mean_test_score']\n",
    "stds = gscv_rfc.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gscv_rfc.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full evaluation set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, gscv_rfc.predict(X_test)\n",
    "print(sklearn.metrics.classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 20}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.558 (+/-0.012) for {'max_depth': 10}\n",
      "0.572 (+/-0.011) for {'max_depth': 20}\n",
      "0.565 (+/-0.017) for {'max_depth': 50}\n",
      "0.568 (+/-0.013) for {'max_depth': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full evaluation set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.68      0.60      2286\n",
      "           1       0.35      0.13      0.19       777\n",
      "           2       0.54      0.61      0.57      2089\n",
      "           3       0.41      0.17      0.24       393\n",
      "           4       0.72      0.70      0.71       692\n",
      "           5       0.38      0.14      0.21       261\n",
      "\n",
      "    accuracy                           0.54      6498\n",
      "   macro avg       0.49      0.40      0.42      6498\n",
      "weighted avg       0.52      0.54      0.51      6498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on different max_depth\n",
    "\n",
    "# by default n_estimator in random forest is 100\n",
    "parameters = {'max_depth': [10, 20, 50, 100]}\n",
    "\n",
    "# use the default 5-fold cross validation. \n",
    "# About CV: For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. \n",
    "# In all other cases, KFold is used.\n",
    "gscv_rfc = sklearn.model_selection.GridSearchCV(sklearn.ensemble.RandomForestClassifier(), parameters)\n",
    "gscv_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(gscv_rfc.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = gscv_rfc.cv_results_['mean_test_score']\n",
    "stds = gscv_rfc.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gscv_rfc.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full evaluation set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, gscv_rfc.predict(X_test)\n",
    "print(sklearn.metrics.classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 20, 'n_estimators': 100}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.549 (+/-0.008) for {'max_depth': 10, 'n_estimators': 10}\n",
      "0.558 (+/-0.014) for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.559 (+/-0.012) for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.559 (+/-0.012) for {'max_depth': 10, 'n_estimators': 200}\n",
      "0.544 (+/-0.017) for {'max_depth': 20, 'n_estimators': 10}\n",
      "0.568 (+/-0.015) for {'max_depth': 20, 'n_estimators': 50}\n",
      "0.572 (+/-0.014) for {'max_depth': 20, 'n_estimators': 100}\n",
      "0.572 (+/-0.011) for {'max_depth': 20, 'n_estimators': 200}\n",
      "0.539 (+/-0.005) for {'max_depth': 50, 'n_estimators': 10}\n",
      "0.563 (+/-0.014) for {'max_depth': 50, 'n_estimators': 50}\n",
      "0.567 (+/-0.009) for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.572 (+/-0.015) for {'max_depth': 50, 'n_estimators': 200}\n",
      "0.536 (+/-0.011) for {'max_depth': 100, 'n_estimators': 10}\n",
      "0.560 (+/-0.016) for {'max_depth': 100, 'n_estimators': 50}\n",
      "0.566 (+/-0.008) for {'max_depth': 100, 'n_estimators': 100}\n",
      "0.569 (+/-0.011) for {'max_depth': 100, 'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full evaluation set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.68      0.60      2286\n",
      "           1       0.36      0.13      0.19       777\n",
      "           2       0.53      0.61      0.57      2089\n",
      "           3       0.43      0.18      0.26       393\n",
      "           4       0.73      0.70      0.72       692\n",
      "           5       0.38      0.13      0.20       261\n",
      "\n",
      "    accuracy                           0.54      6498\n",
      "   macro avg       0.50      0.41      0.42      6498\n",
      "weighted avg       0.52      0.54      0.52      6498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing n_estimators and max_depth\n",
    "\n",
    "# by default n_estimator in random forest is 100\n",
    "parameters = {'max_depth': [10, 20, 50, 100], 'n_estimators':[10, 50, 100, 200]}\n",
    "\n",
    "# use the default 5-fold cross validation. \n",
    "# About CV: For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. \n",
    "# In all other cases, KFold is used.\n",
    "gscv_rfc = sklearn.model_selection.GridSearchCV(sklearn.ensemble.RandomForestClassifier(), parameters)\n",
    "gscv_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(gscv_rfc.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = gscv_rfc.cv_results_['mean_test_score']\n",
    "stds = gscv_rfc.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gscv_rfc.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full evaluation set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, gscv_rfc.predict(X_test)\n",
    "print(sklearn.metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameter found is **{'max_depth': 20, 'n_estimators': 200}**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mode', 'duration', 'distance_m', 'weekday', 'morning', 'midday',\n",
       "       'afternoon', 'evening', 'midnight', 'p_nearby_0', 'p_nearby_1',\n",
       "       'p_nearby_2', 'p_nearby_3', 'p_nearby_4', 'p_nearby_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categorical variables\n",
    "list_categorical_var = ['mode', 'weekday', 'morning', 'midday', 'afternoon', 'evening', 'midnight']\n",
    "mark_cateogrical_var = [e in list_categorical_var for e in X_train.columns]\n",
    "rd_state = 42\n",
    "\n",
    "sm = SMOTENC(random_state=rd_state, categorical_features=mark_cateogrical_var)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number per trip purpose in y_train\n",
      "0    6857\n",
      "2    6268\n",
      "1    2330\n",
      "4    2077\n",
      "3    1178\n",
      "5     783\n",
      "dtype: int64\n",
      "Number per trip purpose in y_train_res\n",
      "0    6857\n",
      "1    6857\n",
      "2    6857\n",
      "3    6857\n",
      "4    6857\n",
      "5    6857\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check number of trip purposes in y_train\n",
    "print(\"Number per trip purpose in y_train\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Number per trip purpose in y_train_res\")\n",
    "print(pd.Series(y_train_res).value_counts())\n",
    "# check number of trip purposes in y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  1.0\n",
      "Accuracy on testing data:  0.5432440751000308\n"
     ]
    }
   ],
   "source": [
    "rf, rf_accuracy_test, rf_pred_test = run_rf(X_train, X_test, y_train, y_test,\\\n",
    "                                                        n_estimators=200, max_depth=20)\n",
    "print(\"Accuracy on training data: \", rf_clf.score(X_train, y_train))\n",
    "print(\"Accuracy on testing data: \", rf_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.68      0.60      2286\n",
      "           1       0.37      0.12      0.19       777\n",
      "           2       0.53      0.61      0.57      2089\n",
      "           3       0.42      0.17      0.24       393\n",
      "           4       0.72      0.70      0.71       692\n",
      "           5       0.39      0.14      0.21       261\n",
      "\n",
      "    accuracy                           0.54      6498\n",
      "   macro avg       0.49      0.41      0.42      6498\n",
      "weighted avg       0.52      0.54      0.52      6498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  0.6537358417189247\n",
      "Accuracy on testing data:  0.5080024622960911\n"
     ]
    }
   ],
   "source": [
    "# compare the model using resampled data and \n",
    "rf_res, rf_res_accuracy_test, rf_res_pred_test = run_rf(X_train_res, X_test, y_train_res, y_test,\\\n",
    "                                                        n_estimators=200, max_depth=20)\n",
    "# print results\n",
    "print(\"Accuracy on training data: \", rf_clf.score(X_train_res, y_train_res))\n",
    "print(\"Accuracy on testing data: \", rf_res_accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding of **purpose** and **mode** is as follows. Note that the trips of home and work have been removed.\n",
    "\n",
    "- purpose: {'leisure': 0, 'food_drink': 1, 'shops': 2, 'pick_up_drop_off': 3, 'education': 4, 'health': 5}\n",
    "- mode: {'walking': 0, 'public_transport': 1, 'car': 2, 'cycling': 3, 'public_transport, car': 4, 'other': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58      2286\n",
      "           1       0.29      0.28      0.28       777\n",
      "           2       0.56      0.51      0.54      2089\n",
      "           3       0.27      0.31      0.29       393\n",
      "           4       0.67      0.72      0.70       692\n",
      "           5       0.20      0.26      0.23       261\n",
      "\n",
      "    accuracy                           0.51      6498\n",
      "   macro avg       0.43      0.44      0.43      6498\n",
      "weighted avg       0.51      0.51      0.51      6498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, rf_res_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oversampling doesn't lead to increase on the prediction accuracy. More predictor variables are needed for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model results\n",
    "#### Functions in this section:\n",
    "1. `model_setup` – Randomises the stratified train/test split and Trip IDs used  \n",
    "2. `merge_predictions_to_data` – Code to join predictions of testing set back to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Globals for columns to keep in the X data\n",
    "BASIC_VARIABLES = ['mode', 'duration', 'distance_m', 'weekday',\n",
    "        'morning', 'midday', 'afternoon', 'evening', 'midnight']\n",
    "TEMPORARY_VARIABLES = ['id_trip','long','lat'] # needed for nearby purpose computation \n",
    "\n",
    "\n",
    "def model_setup(X, y, rd_state):\n",
    "    \"\"\"\n",
    "        Sets up the model by carrying out the train/test splits as well as calculating the nearby purposes columns\n",
    "        :param X: (dataframe) Independent variables\n",
    "        :param y: (dataframe) Dependent variable\n",
    "        :param rd_state: (int) Random state used for stratified train/test split\n",
    "    \"\"\"\n",
    "    ## extract all variables needed based on global column list (see globals)\n",
    "    X = X[BASIC_VARIABLES + TEMPORARY_VARIABLES]\n",
    "    \n",
    "    ## perform stratified train/test split\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        X, y, stratify=y, random_state=rd_state)\n",
    "    \n",
    "    ## compute nearby purposes\n",
    "    X_train, X_test = compute_nearby_purposes(y_train, X_train, X_test, 200)\n",
    "    \n",
    "    ## preserve Trip IDs of training and testing data\n",
    "    X_train_IDs = X_train['id_trip']\n",
    "    X_test_IDs = X_test['id_trip']\n",
    "    \n",
    "    # remove columns which are not needed\n",
    "    X_train = X_train.drop(columns=TEMPORARY_VARIABLES, axis=1)\n",
    "    X_test = X_test.drop(columns=TEMPORARY_VARIABLES, axis=1)\n",
    "    \n",
    "    # flatten y train data\n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X_train_IDs, X_test_IDs\n",
    "\n",
    "\n",
    "def merge_predictions_to_data(original_data, predictions, X_test, y_test, test_ids):\n",
    "    \"\"\"\n",
    "        Merge the predictions made by the model on the testing set back to the original data by merging on the trip ID\n",
    "        :param original_data: (dataframe) Original dataframe from which train-test split is carried out\n",
    "        :param predictions: (array) Predictions made on the testing set\n",
    "        :param test_ids: (array) trip IDs for each row in the testing set\n",
    "        :return original_data_with_preds: (dataframe) New dataframe containing only the testing set trip IDs and with predictions for these\n",
    "    \"\"\"\n",
    "    ## make predictions into dataframe\n",
    "    # apply series to the array of predictions\n",
    "    predictions = pd.Series(predictions)\n",
    "    # make a dataframe of ID, purpose and prediction\n",
    "    prediction_data = pd.DataFrame([test_ids, y_test, predictions]).T\n",
    "    prediction_data.columns = ['id_trip','purpose','prediction']\n",
    "    # join back to X_test\n",
    "    X_test = pd.concat([X_test, prediction_data],axis=1)\n",
    "    \n",
    "    ## merge to original\n",
    "    # get columns to perform merge on (to miss out duplicates)\n",
    "    cols_to_use = list(prediction_data.columns.difference(X_test.columns))\n",
    "    cols_to_use += ['id_trip', 'p_nearby_0','p_nearby_1','p_nearby_2','p_nearby_3','p_nearby_4','p_nearby_5']\n",
    "\n",
    "    # perform inner join\n",
    "    original_data_with_preds = original_data.merge(X_test[cols_to_use], on='id_trip', how='inner')\n",
    "    return original_data_with_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "970\n"
     ]
    }
   ],
   "source": [
    "# set a random seed for train test split\n",
    "random.seed(datetime.datetime.now())\n",
    "rd_state = random.randint(0,1001)\n",
    "print(rd_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.7 s, sys: 324 ms, total: 28 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create new set of train/test data\n",
    "X_train, X_test, y_train, y_test, X_train_IDs, X_test_IDs = model_setup(X_all, y_all, rd_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on testing data: 0.5446291166512773\n"
     ]
    }
   ],
   "source": [
    "# carry out modelling\n",
    "rf, rf_accuracy_test, rf_preds = run_rf(X_train, X_test, y_train, y_test,\\\n",
    "                                                        n_estimators=200, max_depth=20)\n",
    "print('accuracy on testing data:', rf_accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode             2.000000\n",
      "duration       291.000000\n",
      "distance_m    1911.438588\n",
      "weekday          1.000000\n",
      "morning          0.000000\n",
      "midday           0.000000\n",
      "afternoon        1.000000\n",
      "evening          0.000000\n",
      "midnight         0.000000\n",
      "p_nearby_0       0.000000\n",
      "p_nearby_1       0.000000\n",
      "p_nearby_2       1.000000\n",
      "p_nearby_3       0.000000\n",
      "p_nearby_4       0.000000\n",
      "p_nearby_5       0.000000\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_trip</th>\n",
       "      <th>mode</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>duration</th>\n",
       "      <th>weekday</th>\n",
       "      <th>morning</th>\n",
       "      <th>midday</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>midnight</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18820</th>\n",
       "      <td>117483</td>\n",
       "      <td>2</td>\n",
       "      <td>1911.438588</td>\n",
       "      <td>291</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.524062</td>\n",
       "      <td>-73.468883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_trip  mode   distance_m  duration  weekday  morning  midday  \\\n",
       "18820   117483     2  1911.438588       291        1        0       0   \n",
       "\n",
       "       afternoon  evening  midnight        lat       long  \n",
       "18820          1        0         0  45.524062 -73.468883  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DATA CHECK: to see if the ids still match up between the X_test and the original data\n",
    "print(X_test.iloc[0])\n",
    "X_all.loc[X_all.id_trip == X_test_IDs[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge predictions back to data\n",
    "data_with_preds = merge_predictions_to_data(X_all, rf_preds, X_test, y_test, X_test_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_trip</th>\n",
       "      <th>mode</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>duration</th>\n",
       "      <th>weekday</th>\n",
       "      <th>morning</th>\n",
       "      <th>midday</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>midnight</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>p_nearby_0</th>\n",
       "      <th>p_nearby_1</th>\n",
       "      <th>p_nearby_2</th>\n",
       "      <th>p_nearby_3</th>\n",
       "      <th>p_nearby_4</th>\n",
       "      <th>p_nearby_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212877</td>\n",
       "      <td>2</td>\n",
       "      <td>26428.385191</td>\n",
       "      <td>1316</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.632435</td>\n",
       "      <td>-73.318776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142829</td>\n",
       "      <td>0</td>\n",
       "      <td>160.435726</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.504021</td>\n",
       "      <td>-73.571630</td>\n",
       "      <td>0.211957</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.157609</td>\n",
       "      <td>0.016304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256147</td>\n",
       "      <td>6</td>\n",
       "      <td>8329.579052</td>\n",
       "      <td>2254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.566591</td>\n",
       "      <td>-73.576169</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>327454</td>\n",
       "      <td>2</td>\n",
       "      <td>429.696866</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.518120</td>\n",
       "      <td>-73.629446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209312</td>\n",
       "      <td>2</td>\n",
       "      <td>5087.610176</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.563265</td>\n",
       "      <td>-73.751614</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_trip  mode    distance_m  duration  weekday  morning  midday  afternoon  \\\n",
       "0   212877     2  26428.385191      1316        1        0       0          1   \n",
       "1   142829     0    160.435726       217        1        0       0          0   \n",
       "2   256147     6   8329.579052      2254        1        0       0          0   \n",
       "3   327454     2    429.696866       186        1        0       0          0   \n",
       "4   209312     2   5087.610176       779        1        0       0          0   \n",
       "\n",
       "   evening  midnight        lat       long  p_nearby_0  p_nearby_1  \\\n",
       "0        0         0  45.632435 -73.318776    0.000000    0.000000   \n",
       "1        1         0  45.504021 -73.571630    0.211957    0.217391   \n",
       "2        1         0  45.566591 -73.576169    0.272727    0.090909   \n",
       "3        1         0  45.518120 -73.629446    0.000000    0.000000   \n",
       "4        0         1  45.563265 -73.751614    0.333333    0.000000   \n",
       "\n",
       "   p_nearby_2  p_nearby_3  p_nearby_4  p_nearby_5  \n",
       "0    0.000000    0.000000    0.000000    0.000000  \n",
       "1    0.369565    0.027174    0.157609    0.016304  \n",
       "2    0.181818    0.090909    0.181818    0.181818  \n",
       "3    0.000000    0.000000    0.000000    0.000000  \n",
       "4    0.333333    0.333333    0.000000    0.000000  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view data\n",
    "data_with_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append times for start and end of trip\n",
    "start_end_times = gpd.read_file('../../Data/mtl_trajet/mtl_trajet_2017_final.shp')[['id_trip','starttime','endtime']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_preds = data_with_preds.merge(start_end_times, on='id_trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_trip</th>\n",
       "      <th>mode</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>duration</th>\n",
       "      <th>weekday</th>\n",
       "      <th>morning</th>\n",
       "      <th>midday</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>midnight</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>p_nearby_0</th>\n",
       "      <th>p_nearby_1</th>\n",
       "      <th>p_nearby_2</th>\n",
       "      <th>p_nearby_3</th>\n",
       "      <th>p_nearby_4</th>\n",
       "      <th>p_nearby_5</th>\n",
       "      <th>starttime</th>\n",
       "      <th>endtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212877</td>\n",
       "      <td>2</td>\n",
       "      <td>26428.385191</td>\n",
       "      <td>1316</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.632435</td>\n",
       "      <td>-73.318776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-09-18 13:39:44</td>\n",
       "      <td>2017-09-18 14:01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>142829</td>\n",
       "      <td>0</td>\n",
       "      <td>160.435726</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.504021</td>\n",
       "      <td>-73.571630</td>\n",
       "      <td>0.211957</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.157609</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>2017-09-18 17:32:57</td>\n",
       "      <td>2017-09-18 17:36:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256147</td>\n",
       "      <td>6</td>\n",
       "      <td>8329.579052</td>\n",
       "      <td>2254</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.566591</td>\n",
       "      <td>-73.576169</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>2017-09-18 20:07:17</td>\n",
       "      <td>2017-09-18 20:44:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>327454</td>\n",
       "      <td>2</td>\n",
       "      <td>429.696866</td>\n",
       "      <td>186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.518120</td>\n",
       "      <td>-73.629446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-09-18 20:51:21</td>\n",
       "      <td>2017-09-18 20:54:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209312</td>\n",
       "      <td>2</td>\n",
       "      <td>5087.610176</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45.563265</td>\n",
       "      <td>-73.751614</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2017-09-18 22:04:50</td>\n",
       "      <td>2017-09-18 22:17:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_trip  mode    distance_m  duration  weekday  morning  midday  afternoon  \\\n",
       "0   212877     2  26428.385191      1316        1        0       0          1   \n",
       "1   142829     0    160.435726       217        1        0       0          0   \n",
       "2   256147     6   8329.579052      2254        1        0       0          0   \n",
       "3   327454     2    429.696866       186        1        0       0          0   \n",
       "4   209312     2   5087.610176       779        1        0       0          0   \n",
       "\n",
       "   evening  midnight        lat       long  p_nearby_0  p_nearby_1  \\\n",
       "0        0         0  45.632435 -73.318776    0.000000    0.000000   \n",
       "1        1         0  45.504021 -73.571630    0.211957    0.217391   \n",
       "2        1         0  45.566591 -73.576169    0.272727    0.090909   \n",
       "3        1         0  45.518120 -73.629446    0.000000    0.000000   \n",
       "4        0         1  45.563265 -73.751614    0.333333    0.000000   \n",
       "\n",
       "   p_nearby_2  p_nearby_3  p_nearby_4  p_nearby_5            starttime  \\\n",
       "0    0.000000    0.000000    0.000000    0.000000  2017-09-18 13:39:44   \n",
       "1    0.369565    0.027174    0.157609    0.016304  2017-09-18 17:32:57   \n",
       "2    0.181818    0.090909    0.181818    0.181818  2017-09-18 20:07:17   \n",
       "3    0.000000    0.000000    0.000000    0.000000  2017-09-18 20:51:21   \n",
       "4    0.333333    0.333333    0.000000    0.000000  2017-09-18 22:04:50   \n",
       "\n",
       "               endtime  \n",
       "0  2017-09-18 14:01:40  \n",
       "1  2017-09-18 17:36:34  \n",
       "2  2017-09-18 20:44:51  \n",
       "3  2017-09-18 20:54:27  \n",
       "4  2017-09-18 22:17:49  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_with_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data \n",
    "# data_with_preds.to_csv('../../Data/model_outputs/predictions_17.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs many\n",
    "see: https://stackoverflow.com/questions/56090541/how-to-plot-precision-and-recall-of-multiclass-classifier/56092736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create new set of train/test data\n",
    "X_train, X_test, y_train, y_test, X_train_IDs, X_test_IDs = model_setup(X_17, y_17, rd_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.preprocessing.label_binarize(y_train, classes=[0,1,2,3,4,5])\n",
    "y_train = sklearn.preprocessing.label_binarize(y_train, classes=[0,1,2,3,4,5])\n",
    "y_test = sklearn.preprocessing.label_binarize(y_test, classes=[0,1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = sklearn.multiclass.OneVsRestClassifier(sklearn.ensemble.RandomForestClassifier(n_estimators=200,\n",
    "                             max_depth=20,\n",
    "                             random_state=42))\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_score = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision recall curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(6):\n",
    "    precision[i], recall[i], _ = sklearn.metrics.precision_recall_curve(y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='class {}'.format(i))\n",
    "\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"precision vs. recall curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
