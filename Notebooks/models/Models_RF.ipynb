{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trip Purpose Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import rfpimp\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# oversampling\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data should contain the nearby POI information from the Google Place API. \n",
    "\n",
    "`Preprocessing is needed`\n",
    "\n",
    "Consider using the POI types from the paper by Emagun et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_16 = pd.read_csv('../../Data/model_inputs/gdf_2016_X.csv')\n",
    "y_16 = pd.read_csv('../../Data/model_inputs/gdf_2016_y.csv')\n",
    "X_17 = pd.read_csv('../../Data/model_inputs/gdf_2017_X.csv')\n",
    "y_17 = pd.read_csv('../../Data/model_inputs/gdf_2017_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([X_16, X_17],axis=0)\n",
    "y_all = pd.concat([y_16, y_17],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding of **purpose** and **mode** is as follows. Note that the trips of home and work have been removed.\n",
    "\n",
    "- purpose: {'leisure': 0, 'food_drink': 1, 'shops': 2, 'pick_up_drop_off': 3, 'education': 4, 'health': 5}\n",
    "- mode: {'walking': 0, 'public_transport': 1, 'car': 2, 'cycling': 3, 'public_transport, car': 4, 'other': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id_trip', 'mode', 'duration', 'distance_m', 'weekday', 'precip',\n",
       "       'temp', 'morning', 'midday', 'afternoon', 'evening', 'midnight',\n",
       "       'startx', 'starty', 'endx', 'endy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meaning of X variables is shown below.\n",
    "\n",
    "| Variable | Meaning | Unit |\n",
    "|:-------- | :-------- | :---- |\n",
    "| id_trip | Unique ID | NA |\n",
    "| mode | Trip mode | {'walking': 0, 'public_transport': 1, 'car': 2, 'cycling': 3, 'public_transport, car': 4, 'other': 5} |\n",
    "| duration | Trip duration | Second |\n",
    "| distance_m | Euclidean trip distance calculated from nodes along a Shapely LineString object | Metre |\n",
    "| weekday | Whether this trip occurs in a weekday (Monday to Friday) | {1:True, 0:False} |\n",
    "| precip | Total precipitation within a given hour on a given date | mm |\n",
    "| temp | Average Temperature within a given hour on a given date | Celcius |\n",
    "| morning | Whether this trip occurs in the morning time 0600-1059 | {1:True, 0:False} |\n",
    "| afternoon | Whether this trip occurs in the afternoon time 1100-1359 | {1:True, 0:False} |\n",
    "| evening | Whether this trip occurs in the evening time 1700-2159 | {1:True, 0:False} |\n",
    "| midnight | Whether this trip occurs in the midnight time 2200-0559 | {1:True, 0:False} |\n",
    "| startx | The x coordinate of the starting point in the TBC reference system | Metre |\n",
    "| starty | The y coordinate of the starting point in the TBC reference system | Metre |\n",
    "| endx | The x coordinate of the ending point in the TBC reference system | Metre |\n",
    "| endy | The y coordinate of the ending point in the TBC reference system | Metre |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace False and True with 0 and 1, respectively\n",
    "X_all = X_all.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_trip</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>weekday</th>\n",
       "      <th>precip</th>\n",
       "      <th>temp</th>\n",
       "      <th>morning</th>\n",
       "      <th>midday</th>\n",
       "      <th>afternoon</th>\n",
       "      <th>evening</th>\n",
       "      <th>midnight</th>\n",
       "      <th>startx</th>\n",
       "      <th>starty</th>\n",
       "      <th>endx</th>\n",
       "      <th>endy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1889461</td>\n",
       "      <td>1</td>\n",
       "      <td>447</td>\n",
       "      <td>1843.264582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>25.844886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.632056e+06</td>\n",
       "      <td>1.247584e+06</td>\n",
       "      <td>7.630298e+06</td>\n",
       "      <td>1.248129e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2071991</td>\n",
       "      <td>3</td>\n",
       "      <td>844</td>\n",
       "      <td>2761.792383</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>24.930720</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.628002e+06</td>\n",
       "      <td>1.247761e+06</td>\n",
       "      <td>7.626230e+06</td>\n",
       "      <td>1.247150e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1667922</td>\n",
       "      <td>3</td>\n",
       "      <td>1211</td>\n",
       "      <td>1068.301088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>21.769356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.628518e+06</td>\n",
       "      <td>1.246293e+06</td>\n",
       "      <td>7.629432e+06</td>\n",
       "      <td>1.246198e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2072003</td>\n",
       "      <td>0</td>\n",
       "      <td>1266</td>\n",
       "      <td>1394.114250</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.639258</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.628223e+06</td>\n",
       "      <td>1.247461e+06</td>\n",
       "      <td>7.628197e+06</td>\n",
       "      <td>1.246306e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2072007</td>\n",
       "      <td>0</td>\n",
       "      <td>603</td>\n",
       "      <td>552.535139</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.759996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.629631e+06</td>\n",
       "      <td>1.245856e+06</td>\n",
       "      <td>7.630013e+06</td>\n",
       "      <td>1.245629e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_trip  mode  duration   distance_m  weekday    precip       temp  \\\n",
       "0  1889461     1       447  1843.264582        1  0.000134  25.844886   \n",
       "1  2071991     3       844  2761.792383        1  0.001427  24.930720   \n",
       "2  1667922     3      1211  1068.301088        1  0.001429  21.769356   \n",
       "3  2072003     0      1266  1394.114250        0  0.000000  16.639258   \n",
       "4  2072007     0       603   552.535139        0  0.000000  21.759996   \n",
       "\n",
       "   morning  midday  afternoon  evening  midnight        startx        starty  \\\n",
       "0        0       0          0        1         0  7.632056e+06  1.247584e+06   \n",
       "1        0       0          0        1         0  7.628002e+06  1.247761e+06   \n",
       "2        0       0          0        0         1  7.628518e+06  1.246293e+06   \n",
       "3        1       0          0        0         0  7.628223e+06  1.247461e+06   \n",
       "4        0       1          0        0         0  7.629631e+06  1.245856e+06   \n",
       "\n",
       "           endx          endy  \n",
       "0  7.630298e+06  1.248129e+06  \n",
       "1  7.626230e+06  1.247150e+06  \n",
       "2  7.629432e+06  1.246198e+06  \n",
       "3  7.628197e+06  1.246306e+06  \n",
       "4  7.630013e+06  1.245629e+06  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['purpose'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of each trip purpose:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    15479\n",
       "2    13405\n",
       "1     8504\n",
       "4     4437\n",
       "3     3852\n",
       "5     3076\n",
       "Name: purpose, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The size of each trip purpose:')\n",
    "y_all['purpose'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable settings and algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are four settings of variables\n",
    " - Basic (without nearby trip purposes or Google nearby Places)\n",
    " - Basic and nearby trips\n",
    " - Basic and Google POIs\n",
    " - Baisc and nearby trips and Google POIs \n",
    " \n",
    " \n",
    " There are two algorithms:\n",
    " - Random Forest\n",
    " - Nested Logit\n",
    " \n",
    " \n",
    " Based on exhaustive combinations of settings and algorithms, eight models will be trained.\n",
    " \n",
    " In this notebook, we will compare four random forest models. Each model will be tuned using GridSearchCV.\n",
    " \n",
    " The basic variables include the following:\n",
    " - 'mode'\n",
    " - 'duration'\n",
    " - 'distance_m'\n",
    " - 'weekday'\n",
    " - 'precip'\n",
    " - 'temp'\n",
    " - 'morning' \n",
    " - 'midday' \n",
    " - 'afternoon'\n",
    " - 'evening'\n",
    " - 'midnight'\n",
    " \n",
    " \n",
    " There is no need to normalise continuous variables before using RF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function that runs a standard random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(X_train, X_test, y_train, y_test, n_estimators=100, max_depth=None):\n",
    "    \"\"\"\n",
    "        Run a random forest classification model\n",
    "    \"\"\"\n",
    "    clf = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    preds = clf.predict(X_test)\n",
    "    #print(\"Random Forest Classifcation accuracy:\", score)\n",
    "    return clf, score, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A function to compute the proportions of nearby trip purposes in the training data (TK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nearby_purposes(y_train, X_train, X_test, buffer_size_m=200):\n",
    "    \"\"\"\n",
    "        Augment the training and testing data with the proportions of nearby trip purposes in the training data.\n",
    "        :param y_train: (dataframe) the trip purpose of the training data, which is used to compute proportions of nearby trip purposes. Should contain a column of 'purpose'\n",
    "        :param X_train: (dataframe) the predictor variables of the training data. Should contain three columns of 'id', endx' and 'endy'.\n",
    "        :param X_test: (dataframe) the predictor variables of the testing data. Should contain two columns of 'id', 'endx' and 'endy'.\n",
    "        :param buffer_size_m (int) the size of the buffer in metres around each trip end.\n",
    "        :return: (list) [X_train_aug, X_test_aug]. X_train_aug and X_test_aug are the X_train and X_test augmented with extra columns, respectively. The new columns are ['p_nearby_0', 'p_nearby_1', 'p_nearby_2', 'p_nearby_3', 'p_nearby_4', 'p_nearby_5']\n",
    "        Note: when selecting the trips close to a trip in the training data, remember to exclude this trip itself using the 'id' column.\n",
    "        Note: EPSG:3347 == Canada Lambert Projection\n",
    "    \"\"\"\n",
    "    ## merge train and test X back together\n",
    "    all_X = pd.concat([X_train, X_test],axis=0)\n",
    "    \n",
    "    ## initialise a geo-dataframe of all the X values and create a buffer of 200 m around each trip (for each row)\n",
    "    all_X['geometry'] = all_X.apply(lambda row: shapely.geometry.Point(row['endx'],row['endy']),axis=1)\n",
    "    geo_X = gpd.GeoDataFrame(all_X,crs=\"EPSG:3347\")\n",
    "    \n",
    "    # calculate 200 m buffers around each trip end point\n",
    "    geo_X['buffers'] = geo_X['geometry'].apply(lambda row: row.buffer(buffer_size_m))\n",
    "    \n",
    "    # get a geo-dataframe with only the Trip ID,trip end buffer and trip purpose\n",
    "    only_buffers = geo_X[['id_trip','buffers']]\n",
    "    only_buffers = gpd.GeoDataFrame(only_buffers.rename(columns={'buffers':'geometry'}), crs=\"EPSG:3347\")\n",
    "    \n",
    "    \n",
    "    ## intialise a geo-dataframe of only the training data\n",
    "    # Note: only the purposes of trips of the training dataset are known so this is why we need to create a seperate geoDataFrame of only the training data\n",
    "    all_train = pd.concat([X_train,y_train],axis=1)\n",
    "    all_train.reset_index(drop=True,inplace=True)\n",
    "    all_train['geometry'] = all_train.apply(lambda row: shapely.geometry.Point(row['endx'],row['endy']),axis=1)\n",
    "    geo_train = gpd.GeoDataFrame(all_train,crs=\"EPSG:3347\")\n",
    "\n",
    "    ## perform the spatial join between a buffer of each trip and trip end points from exclusively the training data.\n",
    "    # Note: here we are extracting the purpose of trips where the trip end points from the training geo-dataframe (type==Point) intersect with a buffer of all the trip end points (type==Polygon) \n",
    "    joined_data = gpd.sjoin(only_buffers, geo_train, op='intersects', how='left')\n",
    "\n",
    "    ## drop duplicates (as each trip will fall within a buffer of itself)\n",
    "    to_drop = joined_data[['id_trip_left','id_trip_right']].apply(lambda row: True \\\n",
    "                                                                if row['id_trip_left'] == row['id_trip_right']\\\n",
    "                                                                else False, axis=1)\n",
    "    joined_data = joined_data[~to_drop]\n",
    "    \n",
    "    ## Compute the proportion of nearby purposes types for each trip/row\n",
    "    grouped_data = joined_data.groupby(['id_trip_left', 'purpose']).agg({'mode':'count'})\n",
    "    grouped_data = grouped_data.unstack().apply(lambda row: row/row.sum(),axis=1)['mode'].reset_index()\n",
    "    grouped_data = grouped_data.fillna(0.0)\n",
    "    \n",
    "    ## rename columns\n",
    "    new_columns = ['id_trip','p_nearby_0','p_nearby_1','p_nearby_2','p_nearby_3','p_nearby_4',\\\n",
    "                       'p_nearby_5']\n",
    "    grouped_data.columns = new_columns\n",
    "    \n",
    "    ## Merge p_nearby columns back to X_train and X_test\n",
    "    all_X = all_X.merge(grouped_data, on='id_trip', how='left')\n",
    "    all_X = all_X.fillna(0.0)\n",
    "    X_train_aug = X_train.merge(all_X[new_columns], on='id_trip')\n",
    "    X_test_aug = X_test.merge(all_X[new_columns], on='id_trip')\n",
    "    return X_train_aug, X_test_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_variables = ['mode', 'duration', 'distance_m', 'weekday', 'precip',\n",
    "       'temp', 'morning', 'midday', 'afternoon', 'evening', 'midnight']\n",
    "\n",
    "# needed for nearby purpose computation \n",
    "temporary_variables = ['id_trip','endx','endy']\n",
    "\n",
    "# extract all variables\n",
    "X_all_basic_variables = X_all[basic_variables + temporary_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48753, 14)\n",
      "(48753, 1)\n",
      "(48753,)\n"
     ]
    }
   ],
   "source": [
    "print(X_all_basic_variables.shape)\n",
    "print(y_all.shape)\n",
    "print(np.ravel(y_all).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split training testing data\n",
    "rd_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "    X_all_basic_variables, y_all, stratify=y_all, random_state=rd_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compute nearby purposes\n",
    "X_train, X_test =  compute_nearby_purposes(y_train, X_train, X_test, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preserve Trip IDs of training and testing data\n",
    "X_train_IDs = X_train['id_trip']\n",
    "X_test_IDs = X_test['id_trip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns which are not needed\n",
    "X_train = X_train.drop(columns=temporary_variables, axis=1)\n",
    "X_test = X_test.drop(columns=temporary_variables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten y train data\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the random forest algorithm on this dataset\n",
    "rf_clf, rf_accuracy_rest, rf_pred_test = run_rf(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  1.0\n",
      "Accuracy on testing data:  0.5112806628927722\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(\"Accuracy on training data: \", rf_clf.score(X_train, y_train))\n",
    "print(\"Accuracy on testing data: \", rf_accuracy_rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediciton accuracy on the training and testing data is 1.0 and 0.511, respectively, indicating that the model is overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.69      0.58      3870\n",
      "           1       0.44      0.33      0.38      2126\n",
      "           2       0.51      0.57      0.54      3352\n",
      "           3       0.41      0.14      0.21       963\n",
      "           4       0.71      0.59      0.64      1109\n",
      "           5       0.50      0.21      0.29       769\n",
      "\n",
      "    accuracy                           0.51     12189\n",
      "   macro avg       0.51      0.42      0.44     12189\n",
      "weighted avg       0.51      0.51      0.49     12189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that the F1 is the highest for the trips of type 0 and 2, and the lowest for type 3 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_samples is set as 5000 by default. \n",
    "# Setting n_samples as -1 means entire validation set\n",
    "# the score metric used is accuracy, aka number of records that are correctly predicted\n",
    "imp = rfpimp.importances(rf_clf, X_test, y_test, n_samples=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Importance\n",
      "Feature               \n",
      "p_nearby_2    0.047666\n",
      "p_nearby_4    0.045615\n",
      "mode          0.037903\n",
      "midnight      0.027238\n",
      "temp          0.027074\n",
      "p_nearby_0    0.025105\n",
      "weekday       0.024776\n",
      "p_nearby_1    0.012060\n",
      "distance_m    0.010911\n",
      "p_nearby_3    0.007630\n",
      "p_nearby_5    0.007384\n",
      "precip        0.007138\n",
      "duration      0.005333\n",
      "morning       0.004430\n",
      "evening       0.003364\n",
      "afternoon     0.001887\n",
      "midday        0.000984\n"
     ]
    }
   ],
   "source": [
    "print(imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARgAAAEHCAYAAAB1DlnCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZhcVbnv8W9BkCkIoqAoYhBIkDHIGKbLsF4uKIIIGDEo0wEBAYeDGgQ0ip7DVdTrCCcgk4hE1EhEBN4FIvOQQCCAJKDJuUyHwYHBJAik7h9rtdmpVNfQXdVd1fX7PA9PqnftvWtV6Kxn7b3Xb72lcrmMiEg7rDDcDRCRkUsdjIi0jToYEWkbdTAi0jbqYESkbUYNdwM6WalUWh0YA7w6zE0RGUorAQvK5fI/BnsidTC1jbn22msf3HDDDYe7HSJDZv78+ey7775bAA8N9lzqYGp7dcMNN2Ts2LFcetnlLFy0eLjbM2RWW3UVPn74R4e7GTJ8WjJqVwfToIWLFrPX/h8Z7mYMmRuvvmK4myAjgG7yikjbqIMRkbbpikskszAGuNo9bjGIc6wGXAlsBLwO/MY9Tm5NC0Wkmo4fwZiFFVt4unPc46bANsAuZmG/Fp5bRCrUHcHk0cO1wF2kf5jzgI+7x4VV9l0AXAJ8gPQs/VD3+IhZWB34PrBl/swp7vGqfO6fAKvnU5zkHm83C3sAXwaeBsYD7wNGmYVLim0AJuRjDsqfb8AJ7vFDlW3L7f19fv1Ps3AvsH6171wqlY4DjgNWnjZtGmeeeWa9vyYRqaLREcw4YKp73Ap4ETixxr7Pu8f3AucCp+ZtpwM3usftgT2Bb+ZO51nA8v4Tge8VzrMDcLp73KxGG24E3mMW1sn7HAVcVO/LmIW1SJ3gDdXeL5fLU8vl8nbAwRMnTqx3OhHpR6MdzOPu8bb8+jJg1xr7/ir/OYs0CxZgH2CyWZgN3ASsAmxAGuWcbxbmkO6PbFY4z93ucX6tNrjHMmkEdHjuNCYAv6v1RczCKOBnwPfc459r7Ssig9PoTd7KValqrVL1Sv7z9cL5S8DB7nFucUezMAV4Btia1NkVZ7JVTlPurw0XAb/Jx17pHl+r0TaAqcCj7vH/1tlPRAap0RHMBmZhQn59GHBrk59zHXCyWSgBmIVt8vY1gafd4xLgY0CtG7pV2+AenwKeAs4ALq7VCLPwtfyZn26y/SIyAI12MH8EjjALDwBrk+6vNOMs0uXQA2bhwfwzwI/yee8ExrL8qKXRNvyUdAn1cH8Hm4X1SfeCNgPuNQuzzcK/Nfk9RKQJpXpr8rZiDkq7mYUfAPe5xx+38rylUmns3Llz5yqLJL1k3rx5jBs3bly5XJ432HN1xUS7WszCLNLI59+Huy3dTp2KtFrdDsY9LgCWGb2YhelA5RoGX3CP17WuaY1xj9tWbjMLdwErV2z+mHucM9DP6YWwowKO0moDGsH0TWzrVO5xx+Fug4h0QVRARLpXV3QwZmFMfvrUqvPNaOX5RKS6ju9gWhx2xCx8CHi5lecUkep6JuyY3x8NfJYUZPx5ve8uIoPTa2HHs4BvAct1jkWlUum4Uqk0E/jltGnTau0qIjX0TNjRLIwHNnaP0+t8V6WpRVqkl8KOE4Bt82XcKGBds3CTe9yjxncRkUHombCjezzXPb7dPY4hjcDmqXMRaa+eCTuKyNBr9BJpiXs8vt5OeXTQ93omsEd+vQj4RJX9HwW2Kmw6LW+/iXSvpm+/BSx7f6bSrsD59dpXcb6ODW+KjBQKOzZotVVXGfFZndVWXWW4myAjjMKOPUJJaRkOCjs2qNvT1CN99CWdqeOjAiLSvUZ8B2MWFpiFtwx3O0R60YjvYERk+HTkU6RCwPJWYCfgftKM3a8A6wKTgMeAC4F3k7JFx7nHB8zCm0l1j9YB7ibNIu477+HAKcAbSOHNE93j60PzrUR6TyePYDYGvkuaJ7Mp8FHSfJdTgS+SOpv7cvjxi8Cl+bgvA7e6x22AGaTME2bhPaRA5S7ucTwpyjCp2gcr7CjSGp3cwcx3j3NyjOAh4IYcbpxDClHuSgo64h5vBN5sFtYEdieFIXGPvwX+ls+3N7AtcE8OXe5NGv0sR2FHkdboyEuk7JXC6yWFn5eQ2l0t1Fiu+LOoBFziHk9rWQtFpKZOHsHUczP5EicvUPW8e3yxYvt+wJvy/jcAh5iFdfN7a5uFdw11o0V6STd3MFOA7XL48WzgiLz9K8DuZuFe0jo0/w8gByHPAK7Pxziw3lA3WqSX1K3s2MuKlR3PO//Crp/Je/yxRw93M6QLqLLjMOj2sKOCjDIc1ME0SEFBkeapg2nQpZddzsJFi+vv2GZKRUs3UQfToE5JU3fzZZr0nmF7imQWDjALk/t5r25hNLNwgVmotcodZuFis3BIle1jzIKGASJtNmwjGPc4gzSVf6DH/9sgPn4MKXpw+SDOISJ1tKWDaTCsuBmwnXs8ySxsSPrHPiof13eePUjzXZ4nrao3CzjcPZbNwk3Aqe5xplk4BvgCqbrAo8Ar7vGkfJrdzcJngbcBn3ePvyDNm3lPjgxc4h6/046/B5Fe185LpHphxaLvAufmyo//U/HeNsCnSR3Su4Fdim+ahbcDZ5I6MsufVbRe/tz9SR0LwGTgFvc4Xp2LSPu0s4OpF1Ys2oW0xALkAGPB3e7xiXye2VWO3QH4g3v8q3t8lVQhsujX7nFJnsn71kYarjS1SGu0s4OpF1as1N+U4uJ5itUi+5SorXh8vX1TQ5SmFmmJTnlMfRvwEdIyC1XXaKnhbuA7ZuFNwEvAwaRRUi0vAWs020gRaU6nhB0/BXzSLNxDKifbMPf4JPAfpBXqIvAw8EKdwx4AXjML95uFzwygvSLSgBERdjQLo93jy2ZhFDAduNA9Th/seTsx7KjQorRbK8OOnTKCGawp+ZHzg8B84NfD3B4RoXPuwQyKezy13Z/RKWlqpaKlm4yUEYyIdKARMYIZCgo7ijRPIxgRaZuO7mDMwlpm4cThboeIDExHdzDAWoA6GJEu1en3YM4GNsqPoB14FvgwsDIw3T1+uZHktnu82yxMATYC3gG8E/iGezx/SL+NSI/p9BHMZOBPudSrA5uQwo3jgW3Nwu55v0aT21sB7wcmAF/KSezlKOwo0hqd3sEU7ZP/uw+4l9SRbJLfazS5fZV7XOQenwd+T+qslqOwo0hrdPolUlEJ+E/3+F/FjfkSqdHkdmUuovtzEiIdrNNHMMXU83XA0WZhNIBZeEdfGdgmHGgWVjELbwb2AO5pWUtFZDkd3cG4x78At5mFB0mr1V0O3GEW5gC/oPklF+4GfgvcCZzlHp9qZXtFZFkdf4nkHitX//9uld22KOx/ZOH1guJ7wDz3eFwr2yci/evoEYyIdLeOH8G0inucMpjjlaYWaV7PdDDdTiVjpRupg2nQcKepO2H0JNIs3YMRkbbpihFMnkx3tXvcot6+dc6zLXAxsCpwDfCpPONXRNqg40cwZmHFFp7uXOA4UsRgE2DfFp5bRCrUHcEU0sp3kcq4zgM+7h4XVtl3AXAJ8AFgJeBQ9/iIWVgd+D6wZf7MKe7xqnzunwCr51Oc5B5vzzWpvww8TQo2vg8YZRYuKbaBFFo8yT0elD/fgBPc44eqtG094I3u8Y7886XAB4Hf1fs7EJGBaXQEMw6Y6h63Al6k9hotz7vH95JGC32LcZ8O3JhrT+8JfDN3Os8ClvefCHyvcJ4dgNPd42Y12nAjqYj9Onmfo0hLNVTzDuCJws9P5G3LUZpapDUa7WAed4+35deXkZZC6M+v8p+zWJpk3geYnNd1uQlYBdiANMo5P0/9v5JU4L7P3e5xfq025PsnPwEONwtrkUY0/Y1IqpWNrXr/RWlqkdZo9CZvMynkviRzsY50CTjYPc4t7pgXgXoG2JrU2S0uvP2PBttwEfCbfOyV7vG1ftr1BLB+4ef1AWWRRNqo0RHMBmZhQn59GGn1uGZcB5xsFkoAZmGbvH1N4Om8jsvHgFo3dKu2IQcWnwLOID0hqso9Pg28ZBZ2yu34OHBVk99DRJrQaAfzR+AIs/AAsDbp/kozziJdDj2Qk9Fn5e0/yue9ExjL8qOWRtvwU9Il1MN12nECcAHwGPAndINXpK0avURa4h6Pr7eTexxTeD2TtOYK7nER8Ikq+z9KWsayz2l5+02kezV9+y1g2fszlXYF6q6vm9s0qLk0ItK4rphoV4tZmEUa+fx7Oz9nuMOOCjlKN6rbwVRZUwWzMB3YsGLXL7jH61rXtMa4x20rt5mFu0iVB4o+5h7nDE2rWktBR+lWAxrB9E1s61TuccdWn3M4w44KOkq36viogIh0r67oYMzCTWZhuzr7HGkWfjBUbRKR+rqigxGR7tSWp0hm4fPAYvf4PbPwHWBr97iXWdiblBe6lFTadWXSfJSj3OPLeTmFbwOjgeeBI/MEub7zrkCaufu4ezzDLBxFerT9NCkA+Ure7wOkiXdvAP4CTAKeA+YCO7vH5/K55gE75UJsItJi7RrB3Azsll9vB4w2CyuR5qvMIf3jDznkOBP4bH7/+8Ah+cnQhcDXC+ccRZpQNy93LuuROqldSCVNivNkbiV1HNsAVwCfz7OFLyN1NgABuF+di0j7tKuDmUWqHb0GaVRxB6mj2Q1YROoMbsvhxyOAd5HS0lsAnrefwbLZof8CHnSPfZ3OjsBN7vE59/hPoBh7Xh+4LocoPwdsnrdfSIoIABxNP8lrpalFWqMtl0ju8dW8NsxRwO3AA6RlGjYC5gPuHg8rHmMWtgQeco8TqO52YE+z8C332BeK7C90+X3g2+5xRl5bZkpu1+Nm4RmzsBepg5pU7eByuTwVmFoqlcZOnDhxbrV9RKS+dt7kvZm0HszNwC3A8cBsUlXFXczCxgBmYTWzMJZ0f2SdvkCjWVjJLGxeON+PSctcXmkWRpEWwNrDLLw5X14dWth3TeDJ/PqIinZdQLpU+rl7fL1l31ZEltPODuYWYD3gDvf4DGk5hVvc43PAkcDPcnDxTmDTfJlzCPB/zML9pM5o5+IJ3eO3gXtJa8A8QxqZ3AHEvL3PFFJHdAvpZnHRDNJN5P4WphKRFimVy7215nWeT/Md97hbvX1LpdLYuXPnzh07diznnX/hsM7kPf7Yo4fls6X3zJs3j3Hjxo0rl8vzBnuurg87NsMsTCYt2VD13ouItFZPdTDu8Wzg7IEcO5xpaiWppVv1VAczXJSGll6lDqZBg0lTKw0tvUpZJBFpG3UwItI2XXGJ1MLa1F8nRQXe5B5Ht6JtItK/jh/BtLg29W9IFSNFZAj0TG1qAPd4Z96v5nculUrHAccBK0+bNo0zzzyz9l+SiFTVS7WpG6bSsSKt0Uu1qUVkiPVSbWoRGWI9U5taRIZeT9WmNgvfMAtPAKuZhSfyCEpE2qTucg2tmoPSTrlcyX3u8cetPG9xuYZLL7uchYsW1z+oCmWRpJtouYaCoapNrQ5CpHmqTd2ggY5gNHqRXqba1A0aaJpaSWrpZR0fFRCR7tX0CCY/eXkZeCNws3uM/ez3QVKRtJpPdkRk5BrwTV73+KU6u3wQuBpQByPSoxrqYMzC6aRw4eOkGs+zzMLFpMfXvzALZwMHAK8B15PiAgcA/8ssnAEcDOxFChC+AXiMdNN1YT7Pi6TKj28jlXn9Rf7cz5Mm4C0BfuceJ5uFjYAfAusAC4Fj3eMj/bT7YlIlyU1J1SOPItVJmgDc5R6PbOhvSUQGpO49mFyQ/iOkFPOHgO0r3l8bOAjYPAcRv+YebyfVH/qcexzvHv8E/Mo9bu8etyZNmjumcJr1SPmm/cmLcpuF/UijoB3zMd/I+04FTs5Pj04lTdar5U2kzu0zpEjBd0ilZLc0C+OrHaDSsSKt0cgIZjdget/yDGZhRsX7L5JyQBeYhd+SLouq2cIsfA1Yi1T4rPhI+9c5LvCwWXhr3haAi/o+1z3+1SyMJhVju7Kw5ELl4+hKv3GP5RyofKbvUbVZeIgUxpxdeYBKx4q0xkDDjv/iHl8zCzsAe5NGOieRRgyVLgY+6B7vNwtHAnsU3nul8LpU+LPyc1cA/u4eq448+tF37iUVn7OEETDRUKSTNfKY+mbgILOwqllYg7SY1L/kUcWa7vEa4NOkBaIAXgLWKOy6BvB0riPdSOGz64GjzcJq+XPWdo8vAvPNwqF5W8ksbN3AuURkGNTtYNzjvcA00qXEL0k1p4vWAK7OIcQ/kO51AFwBfM4s3JdvzJ5JWhXPgao3ZSs+91rSfZyZeR2ZvsWrJgHH5PrVDwEH1juXiAyPnqtN3YxW1KZWXWnpNgo7DoOBlo5V2VfpZSOig8nzdA6t2Hyle/z6ULdF4UaRpUZEB5M7krZ2Jo2GHRVuFFlKYUcRaRt1MCLSNl1xidTC0rHXkmIJo0iP2z/pHl8ffAtFpJqOH8G0uHTsh3OuaQtSWLLyxrCItFCvlY59sfC930A/EQiVjhVpjZ4rHWsWrsuf+xLwi2r7qHSsSGv0XOlY9/i/SfdhVqZ6KFNEWqQnS8e6x8V52YkDSdkoEWmDnikdaxZGm4X18utRpPs6dUOXIjJwvVQ6dnVgRj7+ftJ9mPOa/B4i0gSVjq1hIKVjlUWSbqc0dYFKx4p0LpWObVAjIxiNXkSWpdKxDWokTa0ktciyOj4qICLdqyvuwbQw7HgTaZLdorxpH/f47OBaJyL96fgOpsVhR4BJ7nFmi88pIlX0VNhRRIZWz4UdgYvMwmyzcGbfzOJKKh0r0hq9Fnac5B63JJXD3Y0UT1iO0tQirdFTYUf3+GT+8yWzcDlplHRpje8iIoPQS2HHUWbhLfn1SsD+wINNfg8RaUIvhR1XBq7Lx88GngTOb/J7iEgTGr1EWuIej6+3k3scU3g9E9gjv14EfKLK/o8CWxU2nZa330S6V9O33wKWvT9TaVfqdBbu8R/AcrECEWmfjp8HU89QhR0bKR2rMrEiy1LYUUTaRmHHBinsKNI8hR1FpG1GfAdjFm4f7jaI9Kqu6mAGEnx0jzu3oy0iUl/HPEXqL1QJPAxcSIob/MAs3AP8kFT6dSFwbA5UvpW0iPe78ylPyMHJl93j6Byg/CrwF1Ku6WbgxDzJT0TaoNNGMP2FKhe7x13d4xXAVODk/PToVNJkPUhByT/k2tPvBR6qcv4dSI+ztwQ2AqqmrhV2FGmNjhnBZJWBxlPy62mQahsBOwNXmoW+Y/oeR+9FGvHgHl8HXqhy/rvd45/zuX5GmqC3XPnYcrk8FZhaKpXGTpw4cW7l+yLSmE7rYPoLNPZFCFYA/u4ex7f4/CLSBp12iVQzVOkeXwTmm4VDAcxCySxsnd++ATghb1/RLLyxyvl3MAsbmoUVSOvPNBvaFJEmdFoH00iochJwjFm4n3Sf5cC8/VPAnnltmVnA5lWOvQM4m5Sing9Mb23zRaSo0y6RqoUqxxR/yItQ7Vt5oHt8hqWdTXH76MKPC92jVpASGSKdNoIRkRGkY0Yw1UKVLT7/TRSWgGiW0tQizeuYDqabqWSsSHXqYBpUK02tFLVIdboHIyJtM6QdjFmYYhZOrb9n3fOsZRZOLPz8drOw3IxcERleHTuCMQu1Lt/WolD8zT0+5R4PaX+rRKQZbb8HYxZOJ2WEHgeeA2blIvSnuseZuZTITPc4xiwcCbyfVJhtdbNwAHAV8CZSVYIz3ONVpMlyG+VCbk5KV1/tHrcwC6uQJuhtB7wGfNY9/j6f+wBgNVLQcbp7/Hy7v79IL2vrCMYsbAt8hLT8woeA7Rs4bAJwhHvci1RM7aBcWnZP4Fu5ttJk4E/ucbx7/FzF8Z8EyBUcDwMuyZ0OpDrXE0lp6olm4Z3VGqA0tUhrtPsSaTfSSGFhzhHNaOAYd49/za9LwH/k6EAE3gG8tc7xu5LKyeIeHwH+m1RzCeAG9/iCe1xMWmfmXdVOoNKxIq0xFPdgqiWWXyt8duXstGLxtUmkhaW2zQnqZ6rsX6lqQfvslcLrYmlbEWmDdncwNwMHmYVVzcIawAfy9gUsLYJW6+bsmsCz7vFVs7AnS0ccLwFr1PjMSQBmYSywAaA1XUSGQVs7GPd4L2mxqNnAL4Fb8lvnACfkBbnfUuMUPwW2MwszSZ3GI/m8fwFuMwsPmoVvVhzzI2DFnKqeBhzpHl9BRIZcqVzWmkv9KZVKY+fOnTt37NixnHf+hTVn8h5/7NFD3DqR9pg3bx7jxo0bVy6X5w32XLoH0aBaYUeFHEWq69iJdt1CQUeR/mkE06D+wo4KOor0TyMYEWmbEdPBmIVrzMJaw90OEVmqay6RzMIo9/haf++7x/cNZXtEpL6hCDuOIZWEvRXYCbgfuAj4CrAuaX7LY6TysO8mlYM9zj0+YBamAG8nLfz9vFm4nn4Ci2ZhASngOBr4Xf68nYEngQPd4yKzsD3wY9Js4VuB/dxj25bpFOl1Q3WJtDHwXWArYFPgo6TM0KnAF0mdzX25ZOwXgUsLx25L6iD6HtU0EljcBPihe9wc+DtwcN5+EXC8e5xAigqISBsNVQcz3z3OyYXmHyKFDsvAHNLopBhQvBF4s1lYMx87wz0uKpyrkcDifPc4O7+eBYzJ92fWcI+35+2X99dYpalFWmOoOpjiVP0lhZ+XkC7TqgUUK8vGVjtXf4HFavvUCkEu+8FKU4u0RKc8RSoGFPcAns/LO7SMe/wb8JJZ2Clvqj7vX0RaplOeIk0BLsrrviwEjmjT5xwDnG8W/kGqkfRCmz5HROixsKNZGO0eX86vJwPrucdP9bd/I2FHBR1lpFHYceDebxZOI33v/waOHN7miIxsPdXBuMdppDVimtZfmlpJapH+9VQH00pKUYvUpw6mQZVpaqWoRerrlMfUIjICjYgOxiwcbxY+PtztEJFljYhLJPd43nC3QUSWN2QdjFk4HDgFeANwF/AA8K5CGvpIUv2jk6vse6J7fN0svEwKTe4PLCKFIJ/JqeuX3eM5uSztXaRKkGsBx7jHW8zCasDFpLDlH0kZqE+6x5nt//YivWlILpHMwntICehdcgG114GXSeVk+0wEpvWz76S8z+rAne5xa1K84Nh+PnKUe9wB+DTw5bztROBvObF9FkvrMi1HYUeR1hiqEczepH/Q95gFgFWBZ4E/52zQo8A44DZSbelq+wL8E7g6v54FWD+f96vCPmPy611Jox/c44M5llBVuVyeCkwtlUpjJ06cqKJtIgM0VB1MCbjEPZ5W3GgWjgE+TCqoNt09lnNx++X2zV7NyzxA7dKvr1TZp+E0tYi0xlA9RboBOMQsrAtgFtY2C+8ijTQ+CBzG0hm2/e07WLeSOjPMwmakBatEpI2GpINxjw8DZwDX50sTJwUN/0ZeNMo93l1r3xY040fAOvmcXyDdZFaaWqSNeiZNbRZWBFZyj4vNwkakkdJY9/jP/o6plaZWilpGKqWpB2Y14PdmYSXS/ZgTanUuyx1cEXZUyFGkvp7pYNzjS6SqAwOiYKNI83qmgxmsSy+7nIWLFgNKUos0Sh1Mg4ppaiWpRRrT1g7GLBwKfBX4H+AzwNvd4zXt/EwR6Rztfkx9DClHtCepYFpT5V3NgkZYIl2sZf+AzcKvgXcCq5Cm5L+NND1/Q7NwDam64qpmYVfgP0lT/r9PmvA2CpjiHq/Kocf35/Osbha+Sqo68DywBWn6/+F51u/ewDn5+HtIT4ZeqbF9AXAJ8AFgJeBQ9/hIq/4ORGRZrRzBHO0etyU9qTkF+CEwE5jkHj8DfAmY5h7H57VxTwdudI/bk5LP3zQLq+dzTQCOcI975Z+3IQUXNyPVr97FLKxCSkdPdI99ndQJ/W0vtPN59/he4FxS6VoRaZNWdjCnmIX7gTtJI5lN6uy/DzDZLMwm1ShaBdggv+fu8a+Ffe92j0/k0rOzSQHGcaQSsX2TgS4Bdq+xvU+1IOQylKYWaY2WXCLlaowBmOAeF+Y1WerNRCsBB7vHZdLKZmFHGisX2194sV6osVoQchlKU4u0RqtGMGuS1lpZaBY2BXaqss9LwBqFn68DTs7paczCNk1+5iOkovYb558/BvyhxnYRGWKt6mCuBUblIOFZpMukSr8HNjMLs83CxLzfSsADZuHB/HPD3ONi4CjgSrMwB1gCnNff9gF+LxEZhJ4JOw5Ef2FHBR1lJGtl2HFEVBUQkc6kiWwNKqaplaQWaYw6mCYo5CjSHHUwDepLUotI43QPRkTapiM7GLNwgFmY3M97L/ez/WKzcEh7WyYizejISyT3OAOYMdztEJHBGfIOxiyMIU3Mu5U04/d+4CLgK8C6pCqOmwHbuceTzMKGwOW5rdcWzlMipbH3AuZTiAiYhS+REtOrArcDnyCFJK/MQUfMwibAFTmgKSJtMFyXSBuTlnTYilQr+qOkpR1OBb5Yse93gXNz6vp/CtsPIgUbtySVkN258N4P3OP27nELUiezv3v8E/CCWRif9zmKlLpejsKOIq0xXB3MfPc4J6ejHwJuyBUb57B8wnkX4Gf59U8K23cHfuYeX3ePTwE3Ft7b0yzclaMCewGb5+0XAEflEiYTSSOj5ZTL5anlcnk74OCJEycO+EuK9Lrh6mCK6eglhZ+XUP2yrb88w3Lb83owPwIOyevBnM/SZPcvgf2A/YFZ7vEvzTddRBrVkU+RKtwG9FU8m1TYfjPwEbOwollYj7RoFSztTJ43C6OBfz1ZykHI60iLTV3U1laLSFd0MJ8CPmkW7iEtC9FnOvAo6bLqXPKSDO7x76RRyxzg16QlM4t+Shr5XN/eZotIz6WpzcKpwJru8cx6+1amqQGlqGXEU+nYATIL04GNSDd+RaTNeqqDcY8HNXnISvPnzwfgxb//DUi9u8hIln/nV2rFuXruEqkZpVJpddJj81eBDwM/H9YGDa1e+76y1ErAnuVy+QeDPZE6mAaVSqWZeW5MT+i17yvLatX//254iiQiXUodjIi0jTqYxk0d7gYMsV77vrKslvz/1z0YEWkbjWBEpG16ah5Mf8zCvqRlIVYELnCPZ1e8X8rvvw9YCBzpHu9t5NhOM8jvuoBUofN14DX3qKdMXaiB34FNSVm99wKnu8dzCu8toInfgZ4fweSlG+N2pFEAAAGvSURBVH5ISllvBhxmFjar2G0/YJP833Gk7FOjx3aMwXzXgj3d43h1Lt2pwd+BvwKnAOdQXcO/Az3fwQA7AI+5xz+7x38CVwAHVuxzIHCpeyy7xzuBtXKCu5FjO8lgvquMDHV/B9zjs+7xHtIE00FRBwPvAB4v/PxE3tbIPo0c20kG810hp9DNwiyzcFzbWintNNjf2aZ+B9TBFNbyLah8tNbfPo0c20kG810BdslrGu9HWkJj91Y2TobEYH9nm/odUAeTevB3Fn5eH3iqwX0aObaTDOa7kpcmxT0+S1qPZ4e2tVTaZVC/s83+DugpUlqQapNcveBJ0up5lfVhZwAnmYUrgB2BF9zj02bhuQaO7SSD+a6rAyu4x5fy632Arw5h26U1GvkdqGogvwM938G4x9fMwkmkpTRXBC50jw+ZhePz++cB15Ae2z5GenR7VK1jh+FrNGQw3xV4KzDdLED6vbncPV6LdJVGfgfMwtuAmcAbgSVm4dOkJ05vocnfAc3kFZG20T0YEWkbdTAi0jbqYESkbdTBiEjbqIMRkbZRByMibaMORkTaRh2MiLTN/wdhCauV3QgZPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x270.72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "viz = rfpimp.plot_importances(imp)\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the most important variables are:\n",
    "- purpose_nearby_2 # shops\n",
    "- purpose_nearby_4 # education\n",
    "- mode\n",
    "- temp\n",
    "- purpose_nearby_0 # leisure\n",
    "- weekday\n",
    "- purpose_nearby_1 # food/drink\n",
    "- distance_m\n",
    "- purpose_nearby_3 # pick-up/drop-off\n",
    "- purpose_nearby_5 # health\n",
    "- midnight\n",
    "- duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter of **n_estimators** will be tuned using *GridSearchCV*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_estimators': 200}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.475 (+/-0.005) for {'n_estimators': 10}\n",
      "0.512 (+/-0.007) for {'n_estimators': 50}\n",
      "0.517 (+/-0.005) for {'n_estimators': 100}\n",
      "0.520 (+/-0.005) for {'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full evaluation set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.59      3870\n",
      "           1       0.45      0.32      0.38      2126\n",
      "           2       0.52      0.58      0.55      3352\n",
      "           3       0.45      0.16      0.24       963\n",
      "           4       0.70      0.60      0.65      1109\n",
      "           5       0.52      0.22      0.31       769\n",
      "\n",
      "    accuracy                           0.52     12189\n",
      "   macro avg       0.53      0.43      0.45     12189\n",
      "weighted avg       0.52      0.52      0.50     12189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on different n_estimators\n",
    "list_n_estimators = [10, 50, 100, 200]\n",
    "\n",
    "# by default n_estimator in random forest is 100\n",
    "parameters = {'n_estimators': list_n_estimators}\n",
    "\n",
    "# use the default 5-fold cross validation. \n",
    "# About CV: For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. \n",
    "# In all other cases, KFold is used.\n",
    "gscv_rfc = sklearn.model_selection.GridSearchCV(sklearn.ensemble.RandomForestClassifier(), parameters)\n",
    "gscv_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(gscv_rfc.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = gscv_rfc.cv_results_['mean_test_score']\n",
    "stds = gscv_rfc.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gscv_rfc.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full evaluation set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, gscv_rfc.predict(X_test)\n",
    "print(sklearn.metrics.classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 10}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.482 (+/-0.009) for {'max_depth': 10}\n",
      "0.478 (+/-0.008) for {'max_depth': 20}\n",
      "0.474 (+/-0.003) for {'max_depth': 50}\n",
      "0.475 (+/-0.005) for {'max_depth': 100}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full evaluation set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.72      0.58      3870\n",
      "           1       0.42      0.25      0.32      2126\n",
      "           2       0.51      0.58      0.54      3352\n",
      "           3       0.42      0.07      0.13       963\n",
      "           4       0.69      0.54      0.61      1109\n",
      "           5       0.52      0.14      0.22       769\n",
      "\n",
      "    accuracy                           0.50     12189\n",
      "   macro avg       0.51      0.38      0.40     12189\n",
      "weighted avg       0.49      0.50      0.47     12189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing on different max_depth\n",
    "\n",
    "# by default n_estimator in random forest is 100\n",
    "parameters = {'max_depth': [10, 20, 50, 100]}\n",
    "\n",
    "# use the default 5-fold cross validation. \n",
    "# About CV: For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. \n",
    "# In all other cases, KFold is used.\n",
    "gscv_rfc = sklearn.model_selection.GridSearchCV(sklearn.ensemble.RandomForestClassifier(), parameters)\n",
    "gscv_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(gscv_rfc.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = gscv_rfc.cv_results_['mean_test_score']\n",
    "stds = gscv_rfc.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gscv_rfc.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full evaluation set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, gscv_rfc.predict(X_test)\n",
    "print(sklearn.metrics.classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/envs/st-ds/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 20, 'n_estimators': 200}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.486 (+/-0.007) for {'max_depth': 10, 'n_estimators': 10}\n",
      "0.494 (+/-0.008) for {'max_depth': 10, 'n_estimators': 50}\n",
      "0.494 (+/-0.007) for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.497 (+/-0.008) for {'max_depth': 10, 'n_estimators': 200}\n",
      "0.476 (+/-0.002) for {'max_depth': 20, 'n_estimators': 10}\n",
      "0.511 (+/-0.004) for {'max_depth': 20, 'n_estimators': 50}\n",
      "0.518 (+/-0.006) for {'max_depth': 20, 'n_estimators': 100}\n",
      "0.522 (+/-0.002) for {'max_depth': 20, 'n_estimators': 200}\n",
      "0.475 (+/-0.004) for {'max_depth': 50, 'n_estimators': 10}\n",
      "0.511 (+/-0.006) for {'max_depth': 50, 'n_estimators': 50}\n",
      "0.517 (+/-0.002) for {'max_depth': 50, 'n_estimators': 100}\n",
      "0.520 (+/-0.002) for {'max_depth': 50, 'n_estimators': 200}\n",
      "0.472 (+/-0.006) for {'max_depth': 100, 'n_estimators': 10}\n",
      "0.512 (+/-0.005) for {'max_depth': 100, 'n_estimators': 50}\n",
      "0.517 (+/-0.008) for {'max_depth': 100, 'n_estimators': 100}\n",
      "0.521 (+/-0.005) for {'max_depth': 100, 'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full evaluation set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.70      0.59      3870\n",
      "           1       0.45      0.32      0.38      2126\n",
      "           2       0.52      0.59      0.56      3352\n",
      "           3       0.46      0.14      0.22       963\n",
      "           4       0.71      0.60      0.65      1109\n",
      "           5       0.56      0.22      0.32       769\n",
      "\n",
      "    accuracy                           0.52     12189\n",
      "   macro avg       0.54      0.43      0.45     12189\n",
      "weighted avg       0.52      0.52      0.50     12189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing n_estimators and max_depth\n",
    "\n",
    "# by default n_estimator in random forest is 100\n",
    "parameters = {'max_depth': [10, 20, 50, 100], 'n_estimators':[10, 50, 100, 200]}\n",
    "\n",
    "# use the default 5-fold cross validation. \n",
    "# About CV: For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, StratifiedKFold is used. \n",
    "# In all other cases, KFold is used.\n",
    "gscv_rfc = sklearn.model_selection.GridSearchCV(sklearn.ensemble.RandomForestClassifier(), parameters)\n",
    "gscv_rfc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(gscv_rfc.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = gscv_rfc.cv_results_['mean_test_score']\n",
    "stds = gscv_rfc.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gscv_rfc.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full evaluation set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, gscv_rfc.predict(X_test)\n",
    "print(sklearn.metrics.classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameter found is **{'max_depth': 20, 'n_estimators': 200}**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mode', 'duration', 'distance_m', 'weekday', 'precip', 'temp',\n",
       "       'morning', 'midday', 'afternoon', 'evening', 'midnight', 'p_nearby_0',\n",
       "       'p_nearby_1', 'p_nearby_2', 'p_nearby_3', 'p_nearby_4', 'p_nearby_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define categorical variables\n",
    "list_categorical_var = ['mode', 'weekday', 'morning', 'midday', 'afternoon', 'evening', 'midnight']\n",
    "mark_cateogrical_var = [e in list_categorical_var for e in X_train.columns]\n",
    "rd_state = 42\n",
    "\n",
    "sm = SMOTENC(random_state=rd_state, categorical_features=mark_cateogrical_var)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number per trip purpose in y_train\n",
      "0    11609\n",
      "2    10053\n",
      "1     6378\n",
      "4     3328\n",
      "3     2889\n",
      "5     2307\n",
      "dtype: int64\n",
      "Number per trip purpose in y_train_res\n",
      "5    11609\n",
      "4    11609\n",
      "3    11609\n",
      "2    11609\n",
      "1    11609\n",
      "0    11609\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check number of trip purposes in y_train\n",
    "print(\"Number per trip purpose in y_train\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"Number per trip purpose in y_train_res\")\n",
    "print(pd.Series(y_train_res).value_counts())\n",
    "# check number of trip purposes in y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data:  0.7140149883710913\n",
      "Accuracy on testing data:  0.49634916728197553\n"
     ]
    }
   ],
   "source": [
    "# compare the model using resampled data and \n",
    "rf_res, rf_res_accuracy_test, rf_res_pred_test = run_rf(X_train_res, X_test, y_train_res, y_test)\n",
    "# print results\n",
    "print(\"Accuracy on training data: \", rf_clf.score(X_train_res, y_train_res))\n",
    "print(\"Accuracy on testing data: \", rf_res_accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding of **purpose** and **mode** is as follows. Note that the trips of home and work have been removed.\n",
    "\n",
    "- purpose: {'leisure': 0, 'food_drink': 1, 'shops': 2, 'pick_up_drop_off': 3, 'education': 4, 'health': 5}\n",
    "- mode: {'walking': 0, 'public_transport': 1, 'car': 2, 'cycling': 3, 'public_transport, car': 4, 'other': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.58      0.56      3870\n",
      "           1       0.42      0.36      0.38      2126\n",
      "           2       0.55      0.53      0.54      3352\n",
      "           3       0.29      0.28      0.29       963\n",
      "           4       0.60      0.64      0.62      1109\n",
      "           5       0.32      0.38      0.35       769\n",
      "\n",
      "    accuracy                           0.50     12189\n",
      "   macro avg       0.45      0.46      0.46     12189\n",
      "weighted avg       0.50      0.50      0.49     12189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, rf_res_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.69      0.58      3870\n",
      "           1       0.44      0.33      0.38      2126\n",
      "           2       0.51      0.57      0.54      3352\n",
      "           3       0.41      0.14      0.21       963\n",
      "           4       0.71      0.59      0.64      1109\n",
      "           5       0.50      0.21      0.29       769\n",
      "\n",
      "    accuracy                           0.51     12189\n",
      "   macro avg       0.51      0.42      0.44     12189\n",
      "weighted avg       0.51      0.51      0.49     12189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The oversampling doesn't lead to increase on the prediction accuracy. More predictor variables are needed for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearby trip RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POI_RF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
