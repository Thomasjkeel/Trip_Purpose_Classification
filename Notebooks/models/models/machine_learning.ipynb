{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models\n",
    "The following classification models are carried out here:\n",
    "    1. Random Forest\n",
    "    2. Support Vector Machines\n",
    "    3. Feed-forward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import sklearn\n",
    "import shapely.wkt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import mplleaflet\n",
    "from scipy.spatial.distance import pdist, squareform, euclidean, directed_hausdorff\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_16 = pd.read_csv('../../../Data/model_inputs/gdf_2016_X.csv')\n",
    "y_16 = pd.read_csv('../../../Data/model_inputs/gdf_2016_y.csv')\n",
    "X_17 = pd.read_csv('../../../Data/model_inputs/gdf_2017_X.csv')\n",
    "y_17 = pd.read_csv('../../../Data/model_inputs/gdf_2017_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_trip</th>\n",
       "      <th>mode_f</th>\n",
       "      <th>duration</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>carddir_f</th>\n",
       "      <th>start_down</th>\n",
       "      <th>end_downto</th>\n",
       "      <th>weekday</th>\n",
       "      <th>temporal_c</th>\n",
       "      <th>precip</th>\n",
       "      <th>temperatur</th>\n",
       "      <th>startrush</th>\n",
       "      <th>endrush</th>\n",
       "      <th>thrurush</th>\n",
       "      <th>startclust</th>\n",
       "      <th>endclust</th>\n",
       "      <th>land_use_s_f</th>\n",
       "      <th>land_use_e_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1724206</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>415.236330</td>\n",
       "      <td>0.227492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>28.012522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889461</td>\n",
       "      <td>1</td>\n",
       "      <td>447</td>\n",
       "      <td>1843.264582</td>\n",
       "      <td>0.470022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>25.844886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1724219</td>\n",
       "      <td>2</td>\n",
       "      <td>591</td>\n",
       "      <td>2657.421830</td>\n",
       "      <td>0.303495</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>25.389363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2071991</td>\n",
       "      <td>3</td>\n",
       "      <td>844</td>\n",
       "      <td>2761.792383</td>\n",
       "      <td>0.223787</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>24.930720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1667922</td>\n",
       "      <td>3</td>\n",
       "      <td>1211</td>\n",
       "      <td>1068.301088</td>\n",
       "      <td>0.293601</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>21.769356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_trip  mode_f  duration   distance_m  magnitude  carddir_f  start_down  \\\n",
       "0  1724206       0       460   415.236330   0.227492          0           1   \n",
       "1  1889461       1       447  1843.264582   0.470022          0           1   \n",
       "2  1724219       2       591  2657.421830   0.303495          1           1   \n",
       "3  2071991       3       844  2761.792383   0.223787          2           1   \n",
       "4  1667922       3      1211  1068.301088   0.293601          3           1   \n",
       "\n",
       "   end_downto  weekday  temporal_c    precip  temperatur  startrush  endrush  \\\n",
       "0           1        1           3  0.000002   28.012522          0        0   \n",
       "1           1        1           5  0.000134   25.844886          1        1   \n",
       "2           1        1           3  0.000240   25.389363          0        0   \n",
       "3           1        1           5  0.001427   24.930720          1        1   \n",
       "4           1        1           4  0.001429   21.769356          0        0   \n",
       "\n",
       "   thrurush  startclust  endclust  land_use_s_f  land_use_e_f  \n",
       "0         0           9         9             0             0  \n",
       "1         1           0         0             1             1  \n",
       "2         0           0         9             1             0  \n",
       "3         1           9         9             0             4  \n",
       "4         0           0         0             0             0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purpose_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purpose_f\n",
       "0          0\n",
       "1          1\n",
       "2          0\n",
       "3          2\n",
       "4          2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15554\n",
       "4    14981\n",
       "1     7430\n",
       "2     5790\n",
       "3     5682\n",
       "5     2473\n",
       "6     2262\n",
       "7     2168\n",
       "Name: purpose_f, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_16['purpose_f'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_setup(data, norm=False, oversample=False):\n",
    "    data['land_use_start_f'] = data['land_use_start'].apply(factorisation, land_use=True)\n",
    "    data['land_use_end_f'] = data['land_use_end'].apply(factorisation, land_use=True)\n",
    "    data['purpose_f'] = data['purpose'].apply(factorisation, purpose=True)\n",
    "    data['mode_f'] = data['mode'].apply(factorisation, mode=True)\n",
    "    data['carddir_f'] = data['carddir'].apply(factorisation, carddir=True)\n",
    "    \n",
    "    X = data[['id_trip',\"mode_f\",\"seconds\",\"distance_m\",\"magnitude\",\"carddir_f\",\"start_down\",\\\n",
    "          \"end_downto\",\"weekday\", \"temporal_c\",\"precip\",\"temperatur\",\\\n",
    "        \"startrush\",\"endrush\",\"thrurush\",\"startclust\",\"endclust\",\"land_use_start_f\",\"land_use_end_f\"]]\n",
    "    y = data[[\"purpose_f\"]] # purpose_labels\n",
    "    X.weekday = X.weekday.astype(int)\n",
    "#     X = np.nan_to_num(X)\n",
    "    feature_list = list(X.columns)\n",
    "    if oversample:\n",
    "        X, y = ros.fit_resample(X, y)\n",
    "    if norm:\n",
    "        X = normalise(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test, feature_list\n",
    "    \n",
    "def normalise(X):\n",
    "    X = X / np.amax(X, axis=0)\n",
    "    return X\n",
    "\n",
    "def subset_to_imp_features(data, above_005):\n",
    "    above_005.append(\"id_trip\")\n",
    "    data = data[data.columns[[col in above_005 for col in data.columns]]]\n",
    "    return data\n",
    "    \n",
    "\n",
    "def run_rf(data, X_train=None, X_test=None, y_train=None, y_test=None, feature_list=None, norm=False, cv=False, oversample=False):\n",
    "    if not X_train:\n",
    "        X_train, X_test, y_train, y_test, feature_list = model_setup(data, norm=norm, oversample=oversample)\n",
    "    try:\n",
    "        X_train.fillna(0, inplace=True)\n",
    "        X_test.fillna(0, inplace=True)\n",
    "    except:\n",
    "        X_train = np.nan_to_num(X_train)\n",
    "        X_test = np.nan_to_num(X_test)\n",
    "    clf = RandomForestClassifier(n_estimators=256, n_jobs=-1)\n",
    "    if cv:\n",
    "        scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "        print(\"Score:\", scores)\n",
    "    else:\n",
    "        clf.fit(X_train, y_train)\n",
    "        scores = clf.score(X_test,y_test)\n",
    "        print(\"Score:\", scores)\n",
    "    return clf, feature_list, scores\n",
    "\n",
    "def calc_feature_imp(clf, feature_list):\n",
    "    # Get numerical feature importances\n",
    "    importances = list(clf.feature_importances_)\n",
    "    # List of tuples with variable and importance\n",
    "    feature_importances = [(feature, round(importance, 5)) for feature, importance in zip(feature_list, importances)]\n",
    "    # Sort the feature importances by most important first\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "    above_005 = [i[0] if i[1] >= 0.05 else \"purpose_f\" for i in feature_importances]\n",
    "    return feature_importances, above_005\n",
    "\n",
    "def plot_feature_imp(feature_importances, title):    \n",
    "    fig, ax = plt.subplots(1, figsize=(10,6))\n",
    "    feat_imp = pd.DataFrame(feature_importances, columns=['importance', 'feature'])\n",
    "    feat_imp = feat_imp.loc[(feat_imp.importance != 'id_trip')]\n",
    "    feat_imp.plot(kind='barh', ax=ax, legend=False)\n",
    "    ax.set_yticklabels([new_column_labels[i] for i in list(feat_imp.importance.values)], size=16);\n",
    "    plt.xticks(size=16);\n",
    "    ax.set_xlim(0,0.2)\n",
    "    ax.axvline(0.05, -10,40, color='r',linestyle='--')\n",
    "    ax.set_xlabel(\"Feature Importance\", size=20)\n",
    "    ax.set_ylabel(\"Feature\", size=20)\n",
    "    ax.set_title(\"{0}\".format(title), size=22)\n",
    "    return ax\n",
    "\n",
    "def encode_inputs(data):\n",
    "    non_code_columns = [\"mode_f\",\"carddir_f\",\"startclust\",\"endclust\", \"purpose_f\", \"id_trip\"]\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    mode_codes = np.array([])\n",
    "    carddir_codes = np.array([])\n",
    "    stcl_codes = np.array([])\n",
    "    encl_codes = np.array([])\n",
    "    land_use_start_codes = np.array([])\n",
    "    land_use_end_codes = np.array([])\n",
    "    if 'mode_f' in data.columns:\n",
    "        mode_codes = enc.fit_transform(data['mode_f'].values.reshape(-1, 1)).toarray()\n",
    "    elif 'land_use_start_f' in data.columns:\n",
    "        data['land_use_start_f'] = data['land_use_start_f'].astype(int)\n",
    "        land_use_start_codes = enc.fit_transform(data['land_use_start_f'].values.reshape(-1, 1)).toarray()\n",
    "    elif 'land_use_end_f' in data.columns:\n",
    "        data['land_use_end_f'] = data['land_use_end_f'].astype(int)\n",
    "        land_use_end_codes = enc.fit_transform(data['land_use_end_f'].values.reshape(-1, 1)).toarray()\n",
    "    elif 'carddir_f' in data.columns:\n",
    "        carddir_codes = enc.fit_transform(data['carddir_f'].values.reshape(-1, 1)).toarray()\n",
    "    elif 'startclust' in data.columns:\n",
    "        stcl_codes = enc.fit_transform(data['startclust'].values.reshape(-1, 1)).toarray()\n",
    "    elif 'endclust' in data.columns:\n",
    "        encl_codes = enc.fit_transform(data['endclust'].values.reshape(-1, 1)).toarray()\n",
    "    if 'weekday' in data.columns:\n",
    "        data['weekday'] = data['weekday'].astype(int)\n",
    "    y_codes = enc.fit_transform(data['purpose_f'].values.reshape(-1, 1)).toarray()\n",
    "    \n",
    "    unique_ids = data['id_trip'].values.reshape(-1,1)\n",
    "    non_codes = data[data.columns[[col not in non_code_columns for col in data.columns]]]\n",
    "    feature_list = list(non_codes)\n",
    "    non_codes = non_codes.values\n",
    "    # normalise\n",
    "    non_codes = non_codes / np.amax(non_codes, axis=0)\n",
    "    other_inputs = {}\n",
    "    # only return codes that are above 0.05 importance\n",
    "    for i, cds in enumerate([non_codes, mode_codes, carddir_codes, stcl_codes, encl_codes, land_use_start_codes, land_use_end_codes, unique_ids]):\n",
    "        if len(cds) != 0:\n",
    "            other_inputs[i] = cds\n",
    "    other_inputs = np.concatenate(tuple(other_inputs.values()), axis=1)\n",
    "    return other_inputs, y_codes\n",
    "\n",
    "def run_mcrf(all_input, y_codes, cv=False, X_train=None, X_test=None, y_train=None, y_test=None):\n",
    "    if type(X_train) == None:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(all_input, y_codes, test_size=0.33, random_state=42)\n",
    "    cv_scores = []\n",
    "    clf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "    multi_target_forest = MultiOutputClassifier(clf, n_jobs=-1)\n",
    "    if cv:\n",
    "        cv_scores = cross_val_score(multi_target_forest, X_train, y_train, cv=5)\n",
    "        \n",
    "    clf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "    multi_target_forest = MultiOutputClassifier(clf, n_jobs=-1)\n",
    "    multi_target_forest.fit(X_train, y_train)\n",
    "    score = multi_target_forest.score(X_test, y_test)\n",
    "    preds = multi_target_forest.predict(X_test)\n",
    "    return cv_scores, score, preds\n",
    "\n",
    "def run_svc(X_train, X_test, y_train, y_test, cv=False):\n",
    "    clf = svm.SVC(gamma=0.01, C=0.1, decision_function_shape='ova')\n",
    "    cv_scores = []\n",
    "    if cv:\n",
    "        cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    clf = svm.SVC(gamma=0.01, C=0.1, decision_function_shape='ova')\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    preds = clf.predict(X_test)  \n",
    "    return cv_scores, score, preds\n",
    "\n",
    "\n",
    "def run_ann(X_train, X_test, y_train, y_test, cv=False):\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(50, 50, 50), random_state=1, max_iter=500)\n",
    "    cv_scores = []\n",
    "    if cv:\n",
    "        cv_scores = cross_val_score(clf,X_train,y_train, cv=5)\n",
    "        clf.fit(X_train, y_train)\n",
    "    clf = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(50, 50, 50), random_state=1, max_iter=500)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    preds = clf.predict(X_test)\n",
    "    return cv_scores, score, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
