{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models\n",
    "The following classification models are carried out here:\n",
    "    1. Random Forest\n",
    "    2. Support Vector Machines\n",
    "    3. Feed-forward Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.model_selection\n",
    "import sklearn.ensemble\n",
    "import sklearn.multioutput\n",
    "import sklearn.neural_network\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_16 = pd.read_csv('../../../Data/model_inputs/gdf_2016_X.csv')\n",
    "y_16 = pd.read_csv('../../../Data/model_inputs/gdf_2016_y.csv')\n",
    "X_17 = pd.read_csv('../../../Data/model_inputs/gdf_2017_X.csv')\n",
    "y_17 = pd.read_csv('../../../Data/model_inputs/gdf_2017_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_trip</th>\n",
       "      <th>mode_f</th>\n",
       "      <th>duration</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>carddir_f</th>\n",
       "      <th>start_down</th>\n",
       "      <th>end_downto</th>\n",
       "      <th>weekday</th>\n",
       "      <th>temporal_c</th>\n",
       "      <th>precip</th>\n",
       "      <th>temperatur</th>\n",
       "      <th>startrush</th>\n",
       "      <th>endrush</th>\n",
       "      <th>thrurush</th>\n",
       "      <th>startclust</th>\n",
       "      <th>endclust</th>\n",
       "      <th>land_use_s_f</th>\n",
       "      <th>land_use_e_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1724206</td>\n",
       "      <td>0</td>\n",
       "      <td>460</td>\n",
       "      <td>415.236330</td>\n",
       "      <td>0.227492</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>28.012522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1889461</td>\n",
       "      <td>1</td>\n",
       "      <td>447</td>\n",
       "      <td>1843.264582</td>\n",
       "      <td>0.470022</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>25.844886</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1724219</td>\n",
       "      <td>2</td>\n",
       "      <td>591</td>\n",
       "      <td>2657.421830</td>\n",
       "      <td>0.303495</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>25.389363</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2071991</td>\n",
       "      <td>3</td>\n",
       "      <td>844</td>\n",
       "      <td>2761.792383</td>\n",
       "      <td>0.223787</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>24.930720</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1667922</td>\n",
       "      <td>3</td>\n",
       "      <td>1211</td>\n",
       "      <td>1068.301088</td>\n",
       "      <td>0.293601</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>21.769356</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_trip  mode_f  duration   distance_m  magnitude  carddir_f  start_down  \\\n",
       "0  1724206       0       460   415.236330   0.227492          0           1   \n",
       "1  1889461       1       447  1843.264582   0.470022          0           1   \n",
       "2  1724219       2       591  2657.421830   0.303495          1           1   \n",
       "3  2071991       3       844  2761.792383   0.223787          2           1   \n",
       "4  1667922       3      1211  1068.301088   0.293601          3           1   \n",
       "\n",
       "   end_downto  weekday  temporal_c    precip  temperatur  startrush  endrush  \\\n",
       "0           1        1           3  0.000002   28.012522          0        0   \n",
       "1           1        1           5  0.000134   25.844886          1        1   \n",
       "2           1        1           3  0.000240   25.389363          0        0   \n",
       "3           1        1           5  0.001427   24.930720          1        1   \n",
       "4           1        1           4  0.001429   21.769356          0        0   \n",
       "\n",
       "   thrurush  startclust  endclust  land_use_s_f  land_use_e_f  \n",
       "0         0           9         9             0             0  \n",
       "1         1           0         0             1             1  \n",
       "2         0           0         9             1             0  \n",
       "3         1           9         9             0             4  \n",
       "4         0           0         0             0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purpose_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purpose_f\n",
       "0          0\n",
       "1          1\n",
       "2          0\n",
       "3          2\n",
       "4          2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15554\n",
       "4    14981\n",
       "1     7430\n",
       "2     5790\n",
       "3     5682\n",
       "5     2473\n",
       "6     2262\n",
       "7     2168\n",
       "Name: purpose_f, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_16['purpose_f'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup model\n",
    "#### Section Overview:\n",
    "2.1  Encode model inputs  \n",
    "2.2  Normalise data and train/test split  \n",
    "2.3  Data preperation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Encode model inputs\n",
    "The model inputs are encoded to improve the performance of models. Specifically by One-hot encoding all the \n",
    "\n",
    "#### Encoded inputs:\n",
    "- Trip mode *(f)*\n",
    "- Cardinal Direction *(f)*\n",
    "- Trip starting & ending cluster from K-means (see `./Notebooks/preprocessing/metric_creation/clustering.ipynb`)\n",
    "- Temporal cluster from LDA\n",
    "- Land-use at trip starting and ending points *(f)* (see `./Notebooks/preprocessing/metric_creation/land_use_poi.ipynb`)\n",
    "\n",
    "*(f) == factors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_model_inputs(data, col):\n",
    "    encoded_input = ''\n",
    "    if col in data.columns:\n",
    "        encoded_input = enc.fit_transform(data[col].values.reshape(-1, 1)).toarray()\n",
    "    return encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = sklearn.preprocessing.OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_inputs = {}\n",
    "for col in [\"mode_f\",\"carddir_f\",\"startclust\",\"endclust\", \"temporal_c\", \"land_use_s_f\", \"land_use_e_f\"]:\n",
    "    encoded_inputs[col] = encode_model_inputs(X_16, col)\n",
    "    \n",
    "encoded_inputs['y_codes'] = encode_model_inputs(y_16, 'purpose_f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56340, 6)\n",
      "(56340, 16)\n",
      "(56340, 12)\n",
      "(56340, 12)\n",
      "(56340, 5)\n",
      "(56340, 10)\n",
      "(56340, 10)\n",
      "(56340, 8)\n"
     ]
    }
   ],
   "source": [
    "for key in encoded_inputs.keys():\n",
    "    print(encoded_inputs[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs['y_codes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Normalise and split training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(X):\n",
    "    X = X / np.amax(X, axis=0)\n",
    "    return X\n",
    "\n",
    "\n",
    "def model_setup(X, y, test_size=0.33, norm=False):\n",
    "    if norm:\n",
    "        X = normalise(X)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=test_size,\\\n",
    "                                                                                random_state=42, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_trip', 'mode_f', 'duration']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = list(X_16.columns)\n",
    "feature_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = model_setup(X_16, y_16, norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flatten data i.e. from Pd.Series to np.array\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# 3. Begin Modelling\n",
    "#### Section Overview:\n",
    "3.1 Define model functions and test modelling   \n",
    "3.2 Preliminary modelling for important feature extraction  \n",
    "3.3 Re-run models  \n",
    "\n",
    "#### Model functions:\n",
    "- `run_rf` == run the random forest classification model.\n",
    "- `run_sv` == run the support vector machine classification model.\n",
    "- `run_ann` == run the multi-layer perceptron classification model.  \n",
    "- `run_mcrf` == *Experimental* run the multi-output random forest classification model.\n",
    "\n",
    "#### Notes:\n",
    "\n",
    "#### Technical Notes:\n",
    "- each model will have a cross-validation option. To use this the function parameters will need to be set to `cv=True` and `cv_val` to the number of k-folds defaulting to `cv_val=5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define model functions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Model functions\n",
    "def run_rf(X_train, X_test, y_train, y_test, n_estimators=10, cv=False, cv_val=5):\n",
    "    cv_scores = []\n",
    "    clf = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators, n_jobs=-1)\n",
    "    if cv:\n",
    "        cv_scores = sklearn.model_selection.cross_val_score(clf, X_train, y_train, cv=cv_val)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test,y_test)\n",
    "    preds = clf.predict(X_test)\n",
    "    print(\"Random Forest Classifcation accuracy:\", score)\n",
    "    return score, preds, cv_scores\n",
    "\n",
    "\n",
    "def run_svc(X_train, X_test, y_train, y_test, gamma_val=0.01, C_val=0.1, cv=False, cv_val=5):\n",
    "    cv_scores = []\n",
    "    if cv:\n",
    "        clf = sklearn.svm.SVC(gamma=gamma_val, C=C_val, decision_function_shape='ova')\n",
    "        cv_scores = sklearn.model_selection.cross_val_score(clf, X_train, y_train, cv=cv_val)\n",
    "    clf = sklearn.svm.SVC(gamma=gamma_val, C=C_val, decision_function_shape='ova')\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    preds = clf.predict(X_test)  \n",
    "    print(\"Support Vector classification accuracy:\", score)\n",
    "    return score, preds, cv_scores\n",
    "\n",
    "\n",
    "def run_ann(X_train, X_test, y_train, y_test, alpha_val=0.01, C_val=0.1, cv=False, cv_val=5):\n",
    "    cv_scores = []\n",
    "    if cv:\n",
    "        clf = sklearn.neural_network.MLPClassifier(solver='lbfgs', alpha=alpha_val,\\\n",
    "                                            hidden_layer_sizes=(50, 50, 50), random_state=1, max_iter=500)\n",
    "        cv_scores = sklearn.model_selection.cross_val_score(clf,X_train,y_train, cv=cv_val)\n",
    "    clf = sklearn.neural_network.MLPClassifier(solver='lbfgs', alpha=alpha_val,\\\n",
    "                                               hidden_layer_sizes=(50, 50, 50), random_state=1, max_iter=500)\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    preds = clf.predict(X_test)\n",
    "    print(\"Neural Network classification accuracy:\", score)\n",
    "    return score, preds, cv_scores\n",
    "\n",
    "\n",
    "## Experimental\n",
    "def run_mcrf(X_train, X_test, y_train, y_test, n_estimators=10, cv=False, cv_val=5):\n",
    "    cv_scores = []\n",
    "    clf = sklearn.ensemble.RandomForestClassifier(n_estimators = n_estimators,\\\n",
    "                                                  criterion = 'entropy', random_state = 42)\n",
    "    multi_target_forest = sklearn.multioutput.MultiOutputClassifier(clf, n_jobs=-1)\n",
    "    if cv:\n",
    "        cv_scores = sklearn.model_selection.cross_val_score(multi_target_forest, X_train, y_train, cv=cv_val)\n",
    "    multi_target_forest.fit(X_train, y_train)\n",
    "    score = multi_target_forest.score(X_test, y_test)\n",
    "    preds = multi_target_forest.predict(X_test)\n",
    "    print(\"Multi-output Random Forest classification accuracy:\", score)\n",
    "    return score, preds, cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifcation accuracy: 0.4178454256978433\n",
      "CPU times: user 1.65 s, sys: 113 ms, total: 1.77 s\n",
      "Wall time: 1.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4178454256978433, array([5, 1, 0, ..., 0, 0, 0]), [])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_rf(X_train, X_test, y_train, y_test,cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifcation accuracy: 0.42618189641262844\n",
      "CPU times: user 2.04 s, sys: 667 ms, total: 2.7 s\n",
      "Wall time: 6.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42618189641262844,\n",
       " array([1, 1, 0, ..., 1, 0, 0]),\n",
       " array([0.42274593, 0.41128178, 0.41780368, 0.422022  , 0.42340313]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_rf(X_train, X_test, y_train, y_test,cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector classification accuracy: 0.27607163986446515\n",
      "CPU times: user 7min 9s, sys: 11.5 s, total: 7min 20s\n",
      "Wall time: 8min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27607163986446515, array([0, 0, 0, ..., 0, 0, 0]), [])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_svc(X_train, X_test, y_train, y_test,cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector classification accuracy: 0.27607163986446515\n",
      "CPU times: user 23min 44s, sys: 47.8 s, total: 24min 32s\n",
      "Wall time: 47min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27607163986446515,\n",
       " array([0, 0, 0, ..., 0, 0, 0]),\n",
       " array([0.27604925, 0.27595339, 0.27606305, 0.27613621, 0.27617281]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_svc(X_train, X_test, y_train, y_test,cv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network classification accuracy: 0.10084440380788469\n",
      "CPU times: user 28.6 s, sys: 2.45 s, total: 31 s\n",
      "Wall time: 22.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10084440380788469, array([3, 3, 3, ..., 3, 3, 3]), [])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_ann(X_train, X_test, y_train, y_test,cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network classification accuracy: 0.10084440380788469\n",
      "CPU times: user 9min 15s, sys: 44.7 s, total: 9min 59s\n",
      "Wall time: 7min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.10084440380788469,\n",
       " array([3, 3, 3, ..., 3, 3, 3]),\n",
       " array([0.19528664, 0.27502648, 0.10941847, 0.16602624, 0.15425391]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "run_ann(X_train, X_test, y_train, y_test,cv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Prepare preliminary RF to subset by feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_imp(clf, feature_list):\n",
    "    # Get numerical feature importances\n",
    "    importances = list(clf.feature_importances_)\n",
    "    # List of tuples with variable and importance\n",
    "    feature_importances = [(feature, round(importance, 5)) for feature, importance in zip(feature_list, importances)]\n",
    "    # Sort the feature importances by most important first\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "    above_005 = [i[0] if i[1] >= 0.05 else \"purpose_f\" for i in feature_importances]\n",
    "    return feature_importances, above_005\n",
    "\n",
    "\n",
    "def subset_to_imp_features(data, above_005):\n",
    "    above_005.append(\"id_trip\")\n",
    "    data = data[data.columns[[col in above_005 for col in data.columns]]]\n",
    "    return data\n",
    "\n",
    "\n",
    "def plot_feature_imp(feature_importances, title):    \n",
    "    fig, ax = plt.subplots(1, figsize=(10,6))\n",
    "    feat_imp = pd.DataFrame(feature_importances, columns=['importance', 'feature'])\n",
    "    feat_imp = feat_imp.loc[(feat_imp.importance != 'id_trip')]\n",
    "    feat_imp.plot(kind='barh', ax=ax, legend=False)\n",
    "    ax.set_yticklabels([new_column_labels[i] for i in list(feat_imp.importance.values)], size=16);\n",
    "    plt.xticks(size=16);\n",
    "    ax.set_xlim(0,0.2)\n",
    "    ax.axvline(0.05, -10,40, color='r',linestyle='--')\n",
    "    ax.set_xlabel(\"Feature Importance\", size=20)\n",
    "    ax.set_ylabel(\"Feature\", size=20)\n",
    "    ax.set_title(\"{0}\".format(title), size=22)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Re-build the models with new subset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics.classification.classification_report(y_true, y_pred, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.model_selection.GridSearchCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
